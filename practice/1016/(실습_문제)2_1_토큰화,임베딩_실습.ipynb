{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Migong0311/TIL/blob/main/practice/1016/(%EC%8B%A4%EC%8A%B5_%EB%AC%B8%EC%A0%9C)2_1_%ED%86%A0%ED%81%B0%ED%99%94%2C%EC%9E%84%EB%B2%A0%EB%94%A9_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4b6a34",
      "metadata": {
        "id": "1f4b6a34"
      },
      "source": [
        "\n",
        "# ğŸ§  í† í¬ë‚˜ì´ì € / ì›Œë“œ ì„ë² ë”©\n",
        "\n",
        "## 1.1 Tokenizer í•™ìŠµ\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* ë¬¸ì¥ì„ ë‹¨ì–´(í† í°) ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬, ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œí† í¬ë‚˜ì´ì €ëŠ” ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ë‚˜ëˆ„ë‚˜ìš”?â€\n",
        "* â€œBPE(Byte Pair Encoding) ë°©ì‹ê³¼ WordPieceì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?â€\n",
        "\n",
        "---\n",
        "\n",
        "## 1.2 í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë³€í™˜\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* í•™ìŠµëœ í† í¬ë‚˜ì´ì €ë¡œ ë¬¸ì¥ì„ ìˆ«ì ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ (`encode`)\n",
        "* ë‹¤ì‹œ ìˆ«ìë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë³µì› (`decode`)\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œ`encode()`ì™€ `decode()`ëŠ” ê°ê° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?â€\n",
        "* â€œíŠ¹ìˆ˜ í† í°([CLS], [SEP], [PAD])ì€ ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©ë˜ë‚˜ìš”?â€\n",
        "\n",
        "---\n",
        "\n",
        "## 1.3 ì„ë² ë”© ë²¡í„°\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* í† í° IDë¥¼ ê³ ì • ê¸¸ì´ì˜ **ì—°ì† ë²¡í„°**ë¡œ ë°”ê¿”ì£¼ëŠ” ì¸µ (e.g., `nn.Embedding`)\n",
        "* ë‹¨ì–´ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆê²Œ í•¨.\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œì„ë² ë”© ë²¡í„°ëŠ” ì™œ í•„ìš”í•œê°€ìš”?â€\n",
        "* â€œì›-í•« ì¸ì½”ë”©ê³¼ ì„ë² ë”©ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?â€\n",
        "* â€œ`nn.Embedding`ì˜ `vocab_size`ì™€ `embedding_dim`ì€ ê°ê° ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?â€\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ” RNN / LSTM\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* ìˆœì°¨ì  ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëŒ€í‘œì ì¸ ìˆœí™˜ ì‹ ê²½ë§ êµ¬ì¡°\n",
        "* LSTMì€ RNNì˜ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ(vanishing gradient)ë¥¼ í•´ê²°í•¨.\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œRNNì´ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì˜ ë‹¤ë£¨ëŠ” ì´ìœ ëŠ” ë­”ê°€ìš”?â€\n",
        "* â€œLSTMì˜ â€˜cell stateâ€™ëŠ” ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?â€\n",
        "* â€œ`nn.RNN`ê³¼ `nn.LSTM`ì˜ ì…ë ¥Â·ì¶œë ¥ í˜•íƒœ ì°¨ì´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.â€\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ¯ Attention Mechanism\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ìš”ì•½í•˜ì§€ ì•Šê³ , ê° ì‹œì ë³„ **ê°€ì¤‘ì¹˜(attention weight)** ë¥¼ ê³„ì‚°í•´ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜.\n",
        "* `LuongAttention`, `BahdanauAttention` ë“±ì´ ëŒ€í‘œì .\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œAttentionì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?â€\n",
        "* â€œLuong ì–´í…ì…˜ê³¼ Bahdanau ì–´í…ì…˜ì˜ ì°¨ì´ì ì€?â€\n",
        "* â€œì–´í…ì…˜ ê°€ì¤‘ì¹˜ëŠ” ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?â€\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ¤— HuggingFace ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸(`BERT`, `GPT`, `T5`, `RoBERTa` ë“±)ì„ ê°„í¸í•˜ê²Œ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬.\n",
        "* Tokenizer, Model, Trainer ë“± ê³ ìˆ˜ì¤€ API ì œê³µ.\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œ`from_pretrained()` ë©”ì„œë“œëŠ” ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?â€\n",
        "* â€œHuggingFaceì˜ `pipeline`ì„ ì´ìš©í•˜ë©´ ì–´ë–¤ ì¼ì„ ìë™í™”í•  ìˆ˜ ìˆë‚˜ìš”?â€\n",
        "* â€œ`tokenizer`, `model`, `trainer`ëŠ” ê°ê° ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?â€\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ§© ì•„í‚¤í…ì²˜ë³„ ëª¨ë¸ ë‹¤ë¤„ë³´ê¸° (Encoder / Decoder)\n",
        "\n",
        "**í•µì‹¬ ê°œë…**\n",
        "\n",
        "* **Encoder ëª¨ë¸**: ì…ë ¥ì„ ì¸ì½”ë”©(ìš”ì•½)í•˜ëŠ” ì—­í•  (e.g., BERT)\n",
        "* **Decoder ëª¨ë¸**: ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„± (e.g., GPT, T5)\n",
        "* **Seq2Seq êµ¬ì¡°**: Encoderì™€ Decoderë¥¼ ì—°ê²°í•´ ë¬¸ì¥ ë³€í™˜/ë²ˆì—­ ë“±ì— í™œìš©\n",
        "\n",
        "**ì§ˆë¬¸ ì˜ˆì‹œ**\n",
        "\n",
        "* â€œEncoderì™€ Decoderì˜ êµ¬ì¡°ì  ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?â€\n",
        "* â€œBERTì™€ GPTëŠ” ê°ê° ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë‚˜ìš”?â€\n",
        "* â€œSeq2Seq êµ¬ì¡°ì—ì„œ Attentionì´ ì–´ë””ì— ë“¤ì–´ê°€ë‚˜ìš”?â€\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add5dacf",
      "metadata": {
        "id": "add5dacf"
      },
      "source": [
        "### **Objectives**\n",
        "\n",
        "1. ì‹¤ìŠµëª…: í† í°í™”/ì„ë² ë”© ì‹¤ìŠµ\n",
        "2. í•µì‹¬ ì£¼ì œ\n",
        "    1) tokenizerë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ì–´ë“¤ì„ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
        "    2) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
        "    3) RNNë¶€í„° íŠ¸ëœìŠ¤í¬ë¨¸ê¹Œì§€ ëª¨ë¸ì˜ ë°œì „ì‚¬ë¥¼ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ìš”ì†Œ ê¸°ìˆ ì˜ ì—­í• ì„ ì´í•´\n",
        "3. í•™ìŠµ ëª©í‘œ\n",
        "    1) í† í¬ë‚˜ì´ì €ê°€ ë¬´ì—‡ì´ê³  í† í°í™”ê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    2) í† í°í™”ë¥¼ ì™œ í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    3) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "    4) ì„ë² ë”© ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ ì–´ë–¤ ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    5) ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ë°œì „ì‚¬ì— ëŒ€í•´ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "4. í•™ìŠµ ê°œë…\n",
        "    1) í† í°í™”:\n",
        "    2) ì„ë² ë”© ë²¡í„°:\n",
        "    3) ì¸ì½”ë”/ë””ì½”ë”:\n",
        "  \n",
        "5. í•™ìŠµ ë°©í–¥\n",
        "    - ì‹¤ìŠµì€ ì•„ë˜ ë‚´ìš©ë“¤ì„ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
        "      - í† í°í™”\n",
        "      - ì„ë² ë”©\n",
        "      - RNN\n",
        "      - LSTM\n",
        "      - ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\n",
        "      - ì¸ì½”ë”\n",
        "      - ë””ì½”ë”\n",
        "    - ì‹¤ìŠµ ì½”ë“œëŠ” ì¡°êµê°€ ì§ì ‘ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ë©° í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "    - ìì—°ìŠ¤ëŸ½ê²Œ ì½”ë“œë¥¼ êµ¬í˜„í•˜ë©´ì„œ ì•„í‚¤í…ì³ì˜ ë°œì „ì‚¬ë¥¼ ì²´í—˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "6. ë°ì´í„°ì…‹ ê°œìš” ë° ì €ì‘ê¶Œ ì •ë³´\n",
        "    - ë°ì´í„°ì…‹ ëª… : NSMC(Naver Sentiment Movie Corpus)\n",
        "    - ë°ì´í„°ì…‹ ê°œìš” : ë„¤ì´ë²„ ì˜í™” ê°ì •ë¶„ì„ ë°ì´í„°ì…‹\n",
        "    - ë°ì´í„°ì…‹ ì €ì‘ê¶Œ : CC0 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c26eeb4b",
      "metadata": {
        "id": "c26eeb4b"
      },
      "source": [
        "### **Prerequisites**\n",
        "```\n",
        "numpy==2.0.2\n",
        "pandas==2.2.2\n",
        "tokenizers==0.21.4\n",
        "transformers==4.55.2\n",
        "torch==2.8.0+cu126\n",
        "```\n",
        "\n",
        "- ë§Œì•½, ê¸°ë³¸ ì½”ë©ê³¼ ë²„ì „ì´ ë‹¤ë¥´ë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•´ì„œ ì‹¤í–‰ì‹œì¼œì£¼ì„¸ìš”.\n",
        "```\n",
        "%pip install numpy==2.0.2 pandas==2.2.2 tokenizers==0.21.4 transformers==4.55.2 torch==2.8.0+cu126 --index-url https://download.pytorch.org/whl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "b1260a59",
      "metadata": {
        "id": "b1260a59"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from typing import (\n",
        "    Generic,\n",
        "    Tuple,\n",
        "    TypeVar,\n",
        "    List,\n",
        "    Union,\n",
        "    get_args\n",
        ")\n",
        "# ì‹œë“œ ì„¤ì •\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "Batch = TypeVar(\"Batch\", bound=int)\n",
        "Token = TypeVar(\"Token\", bound=int)\n",
        "Sequence = TypeVar(\"Sequence\", bound=int)\n",
        "Layers = TypeVar(\"Layers\", bound=int)\n",
        "HiddenStates = TypeVar(\"HiddenStates\", bound=int)\n",
        "VocabSize = TypeVar(\"VocabSize\", bound=int)\n",
        "EmbeddingSize = TypeVar(\"EmbeddingSize\", bound=int)\n",
        "MaxLength = TypeVar(\"MaxLength\", bound=int)\n",
        "\n",
        "_1D = TypeVar(\"_1D\")\n",
        "_2D = TypeVar(\"_2D\")\n",
        "_3D = TypeVar(\"_3D\")\n",
        "\n",
        "def _label_str(self) -> str:\n",
        "    \"\"\"ì¸ìŠ¤í„´ìŠ¤ì˜ ì œë„¤ë¦­ ë¼ë²¨ ì´ë¦„ì„ ì˜ˆì˜ê²Œ í‘œì‹œ (e.g., [Sequence])\"\"\"\n",
        "    oc = getattr(self, \"__orig_class__\", None)\n",
        "    if oc is None:\n",
        "        return \"[]\"\n",
        "    args = get_args(oc)\n",
        "    names = [getattr(a, \"__name__\", str(a)) for a in args]\n",
        "    return \"[\" + \", \".join(names) + \"]\"\n",
        "\n",
        "\n",
        "class Tensor1D(Generic[_1D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 1, ValueError(\"Tensor must be 1-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.s: _1D = tensor.size(0)  # sequence length\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.s}))\"\n",
        "\n",
        "class Tensor2D(Generic[_1D, _2D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 2, ValueError(\"Tensor must be 2-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}))\"\n",
        "\n",
        "\n",
        "class Tensor3D(Generic[_1D, _2D, _3D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 3, ValueError(\"Tensor must be 3-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        self.h: _3D = tensor.size(2)  # hidden state size\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "        assert self.h == tensor.size(2), ValueError(\n",
        "            f\"Expected Hidden State {self.h}, but got {tensor.size(2)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}, {self.h}))\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d55eb901",
      "metadata": {
        "id": "d55eb901"
      },
      "source": [
        "# 1. í† í¬ë‚˜ì´ì € / ì›Œë“œ ì„ë² ë”©\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.\n",
        "  2. í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆã….\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. í† í¬ë‚˜ì´ì €\n",
        "  2. í† í°í™”\n",
        "  3. ì„ë² ë”©\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. ì œê³µëœ ë§ë­‰ì¹˜ë¡œ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ì½”ë“œ í•œ ì¤„ì„ ì™„ì„±\n",
        "  2. í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ íŠ¹ì • ë¬¸ì¥ì„ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ\n",
        "  3. nn.Embedding ë ˆì´ì–´(í˜¹ì€ ê°„ë‹¨í•œ dict lookup)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì½”ë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42fdfec",
      "metadata": {
        "id": "c42fdfec"
      },
      "source": [
        "### 1.1. Tokenizer í•™ìŠµ\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì € í•™ìŠµ</b><br>\n",
        "ì–¸ì–´ ëª¨ë¸ì—ì„œ í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒ ë‘ê°€ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "1. í† í¬ë‚˜ì´ì € ê°ì²´(í´ë˜ìŠ¤)\n",
        "2. í•™ìŠµ ë°ì´í„°\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc62bac",
      "metadata": {
        "id": "9cc62bac"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ìš°ì„  í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•™ìŠµí•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” íŒŒì¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” NSMC(Naver Sentiment Movie Corpus) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "97b7effd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97b7effd",
        "outputId": "5350b2e7-2dca-4caa-a4b9-4d2778cf3fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-17 07:56:18--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n",
            "--2025-10-17 07:56:19--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19515078 (19M) [text/plain]\n",
            "Saving to: â€˜ratings.txt.4â€™\n",
            "\n",
            "ratings.txt.4       100%[===================>]  18.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-17 07:56:19 (125 MB/s) - â€˜ratings.txt.4â€™ saved [19515078/19515078]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/e9t/nsmc/raw/master/ratings.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facaabde",
      "metadata": {
        "id": "facaabde"
      },
      "source": [
        "ë°ì´í„°ì…‹ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "dd94219a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "dd94219a",
        "outputId": "836cba2d-76e1-482a-9785-3d6b93935b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤! ratings.txt\n",
            "ë¦¬ë·° ê°¯ìˆ˜ : 199992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹      1\n",
              "1   8132799  ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...      1\n",
              "2   4655635               í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .      1\n",
              "3   9251303  ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...      1\n",
              "4  10067386                        ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a9e55e0-71da-4716-a250-5cb16fc3dddc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9e55e0-71da-4716-a250-5cb16fc3dddc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a9e55e0-71da-4716-a250-5cb16fc3dddc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a9e55e0-71da-4716-a250-5cb16fc3dddc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-059aac59-16b6-46cb-86b6-5b2f01a41849\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-059aac59-16b6-46cb-86b6-5b2f01a41849')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-059aac59-16b6-46cb-86b6-5b2f01a41849 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_list = os.listdir()\n",
        "for file in file_list:\n",
        "    if \"ratings.txt\" == file:\n",
        "        print('í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!', file)\n",
        "        df = pd.read_table( (os.getcwd() + '/' + file), encoding='utf-8') # ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³´ê¸° í¸í•˜ê²Œ ë°”ê¿”ì¤ì‹œë‹¤!\n",
        "        df = df.dropna(how = 'any') # ë„ê°’ì„ ì—†ì• ì¤ë‹ˆë‹¤!\n",
        "        print('ë¦¬ë·° ê°¯ìˆ˜ :', len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3146be",
      "metadata": {
        "id": "ed3146be"
      },
      "source": [
        "í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” 'document'ì—´ë§Œì„ ê°€ì ¸ì˜¤ê³ \n",
        "\n",
        "í•´ë‹¹ ë°ì´í„°ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "c0224daf",
      "metadata": {
        "id": "c0224daf"
      },
      "outputs": [],
      "source": [
        "with open((os.getcwd() + '/' + 'naver_review.txt'), 'w', encoding='utf8') as f:\n",
        "    # TODO: document ì—´ë§Œ ê°€ì ¸ì™€ì„œ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "    # FIXME\n",
        "\n",
        "     for line in df['document']:\n",
        "        # None, NaN ê°™ì€ ê²°ì¸¡ì¹˜ ë°©ì§€\n",
        "        if pd.notnull(line):\n",
        "            f.write(str(line).strip() + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252458b8",
      "metadata": {
        "id": "252458b8"
      },
      "source": [
        "í•™ìŠµì´ ë˜ì–´ ìˆì§€ ì•Šì€ ë¹ˆ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” BertWordPieceTokenizerë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "\n",
        "##### íŒŒë¼ë¯¸í„°:\n",
        "- `strip_accents` : ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì•…ì„¼íŠ¸(ì•¡ì„¼íŠ¸)ë¥¼ ì œê±°í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¥¼ í•™ìŠµí• ë•Œì—ëŠ” `False`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "- `lowercase` : ì˜ì–´ë¥¼ ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¿‰ë‹ˆë‹¤. `False`ë¡œ ì„¤ì •í•˜ë©´ ì˜ì–´ë¥¼ ëŒ€ë¬¸ìë¡œ ìœ ì§€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "9d919be5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d919be5",
        "outputId": "9e4473a2-02a5-4f2a-a2bd-822b2548c5ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=##)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# ë¹ˆ tokenizer ìƒì„± : vocabulary_size = 0 ì¸ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "    lowercase=False,\n",
        "    strip_accents=False,\n",
        ")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4e500b",
      "metadata": {
        "id": "3a4e500b"
      },
      "source": [
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "#### íŒŒë¼ë¯¸í„° ì„¤ëª…:\n",
        "- `data_file` : ë°ì´í„° ê²½ë¡œë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤. list í˜•íƒœë¡œ ì—¬ëŸ¬ê°œì˜ íŒŒì¼ì„ ì§€ì •í•´ì¤„ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "- `vocab_size (default: 30000)` : ë‹¨ì–´ì‚¬ì „ í¬ê¸°ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë– í•œ ê°’ì´ ê°€ì¥ ì¢‹ë‹¤ëŠ” ê²ƒì€ ì—†ì§€ë§Œ, ê°’ì´ í´ìˆ˜ë¡ ë§ì€ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë‹´ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- `initial_alphabet` : ê¼­ í¬í•¨ëìœ¼ë©´ í•˜ëŠ” initial alphabetì„ í•™ìŠµ ì „ì— ì¶”ê°€í•´ì¤ë‹ˆë‹¤.\n",
        "    - initialì€ í•™ìŠµí•˜ê¸° ì´ì „ì— ë¯¸ë¦¬ ë‹¨ì–´ë¥¼ vocabì— ë„£ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "    - special tokenë“¤ë„ initialì— vocabì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
        "- `limit_alphabet (default: 1000)` : initial tokensì˜ ê°¯ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
        "- `min_frequency (default: 2)` : ìµœì†Œ ë¹ˆë„ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë§Œì•½ ì–´ë–¤ ë‹¨ì–´ê°€ 1ë²ˆ ë‚˜ì˜¤ë©´ vocabì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "- `special_tokens` : íŠ¹ìˆ˜ í† í°ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.. BERTì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í† í°ì´ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.\n",
        "    - `[PAD]` : íŒ¨ë”©ì„ ìœ„í•œ í† í°\n",
        "    - `[UNK]` : OOV ë‹¨ì–´ë¥¼ ìœ„í•œ í† í°\n",
        "    - `[CLS]` : ë¬¸ì¥ì˜ ì‹œì‘ì„ ì•Œë¦¬ê³  ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” í† í°\n",
        "    - `[SEP]` : ë¬¸ì¥ ì‚¬ì´ì‚¬ì´ë¥¼ êµ¬ë³„í•´ì£¼ëŠ” í† í°\n",
        "    - `[MASK]` : MLM íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë§ˆìŠ¤í¬ í† í°\n",
        "- `wordpiece_prefix(default: '##')` : sub-wordë¼ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ëŠ” í‘œì‹œì…ë‹ˆë‹¤.\n",
        "    - BERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ '##'ì„ ì”ë‹ˆë‹¤.\n",
        "    - ì˜ˆë¥¼ ë“¤ì–´, `SS, ##AF, ##Y` ì²˜ëŸ¼ sub-wordë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ '##'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "- `show_progress` : í•™ìŠµ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "82aa578c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82aa578c",
        "outputId": "9a914edc-7143-489c-bc53-f059c54ebb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size :  30000\n",
            "['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']\n"
          ]
        }
      ],
      "source": [
        "data_file = 'naver_review.txt'\n",
        "vocab_size = 30000\n",
        "min_frequency = 2\n",
        "initial_alphabet = []\n",
        "limit_alphabet = 6000\n",
        "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "wordpieces_prefix = \"##\"\n",
        "show_progress=True\n",
        "\n",
        "tokenizer.train(\n",
        "    files = data_file,\n",
        "    vocab_size = vocab_size,\n",
        "    min_frequency = min_frequency,\n",
        "    initial_alphabet = initial_alphabet,\n",
        "    limit_alphabet = limit_alphabet,\n",
        "    special_tokens = special_tokens,\n",
        "    wordpieces_prefix = wordpieces_prefix,\n",
        "    show_progress = True,\n",
        ")\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(\"vocab size : \", len(vocab))\n",
        "print(sorted(vocab, key=lambda x: vocab[x])[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83244f41",
      "metadata": {
        "id": "83244f41"
      },
      "source": [
        "### 1.2. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜</b><br>\n",
        "ëª¨ë¸ì´ í† í°ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì •ìˆ˜ê°’ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "a26d8b6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26d8b6b",
        "outputId": "ad504d24-78ab-40d2-bab8-6d976661a00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ±í† í°í™” ê²°ê³¼ : ['I', \"'\", 'm', 'a', 'st', '##ud', '##ent', 'of', 'S', '##S', '##A', '##F', '##Y', '!']\n",
            "ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© : [45, 11, 81, 69, 15444, 24900, 16071, 10280, 55, 3890, 4047, 3976, 4755, 5]\n",
            "ğŸŒˆë””ì½”ë”© : I ' m a student of SSAFY!\n"
          ]
        }
      ],
      "source": [
        "text = \"I'm a student of SSAFY!\"\n",
        "\n",
        "encoded = tokenizer.encode(text)\n",
        "print('ğŸŒ±í† í°í™” ê²°ê³¼ :',encoded.tokens)\n",
        "print('ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© :',encoded.ids)\n",
        "print('ğŸŒˆë””ì½”ë”© :',tokenizer.decode(encoded.ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884cec1b",
      "metadata": {
        "id": "884cec1b"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ ëª¨ë¸ ì…ë ¥ ë§Œë“¤ê¸°</b><br>\n",
        "ê·¸ë ‡ë‹¤ë©´ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í† í¬ë‚˜ì´ì§•ì„ í•´ì•¼ í• ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "ìœ„ì— ëŒ€í•œ ë‹µë³€ì€ ì•ìœ¼ë¡œ ì‹¤ìŠµ ì½”ë“œë¥¼ ì§„í–‰í•˜ë©´ì„œ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì— ì´ ì ì„ ìŠì§€ ë§ê³  ê³„ì† ë”°ë¼ê°€ì‹œê¸° ë°”ëë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a906dbd",
      "metadata": {
        "id": "7a906dbd"
      },
      "source": [
        "### 1.3. ì„ë² ë”© ë²¡í„°\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í° IDì— ë”°ë¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë²¡í„°í™”ê°€ ë ê¹Œìš”?</b><br>\n",
        "í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ íŠ¹ì • í† í° IDì— ë”°ë¥¸ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì„ë² ë”© ë²¡í„°ëŠ” torchì˜ nn.Embedding ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë©ë‹ˆë‹¤. í•´ë‹¹ ì„ë² ë”© ë²¡í„°ëŠ” ëª¨ë‘ ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "db1e9b06",
      "metadata": {
        "id": "db1e9b06"
      },
      "outputs": [],
      "source": [
        "# embedding_vector = nn.Embedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e6473c",
      "metadata": {
        "id": "e7e6473c"
      },
      "source": [
        "ì„ë² ë”© ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•˜ë ¤ê³  í•˜ë‹ˆ ë‹¤ìŒ ë‘ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ë°˜ë“œì‹œ ë„£ìœ¼ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. `num_embeddings`: ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸° (size of the dictionary of embeddings)\n",
        "2. `embedding_dim`: ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› (the size of each embedding vector)\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  num_embeddings </b><br>\n",
        "ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸°ëŠ” ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "ì—¬ê¸°ì„œ `num_embeddings`ëŠ” ê³ ìœ í•œ í† í°(ë‹¨ì–´, ë¬¸ì ë“±)ì˜ ì´ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì–´ë–¤ `ì¸ë±ìŠ¤ â†’ ë²¡í„°` ë§¤í•‘ í…Œì´ë¸”ì„ ë§Œë“¤ ê±´ë°, ê·¸ í…Œì´ë¸”ì— ëª‡ ê°œì˜ í•­ëª©ì´ ë“¤ì–´ê°€ì•¼ í•˜ëŠ”ì§€ë¥¼ ì •ì˜í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. tokenizerë¥¼ ë§Œë“¤ë•Œ `vocab_size`ì™€ ë™ì¼í•œ ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  embedding_dim </b><br>\n",
        "ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ì€ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "`embedding_dim`ì€ ê° ë‹¨ì–´(ë˜ëŠ” í† í°)ê°€ í‘œí˜„ë˜ëŠ” ë²¡í„°ì˜ ê¸¸ì´ì…ë‹ˆë‹¤. ì¦‰, í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì–´ë–¤ ìˆ«ì ë²¡í„°ë¡œ ë‚˜íƒ€ë‚¼ ë•Œ ê·¸ ë²¡í„°ê°€ ëª‡ ì°¨ì›ì¸ì§€ ì •í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. ë³´í†µì˜ embeddingì€ `768`, `1024` ë“± 2ì˜ ì œê³±ìˆ˜ ì°¨ì›ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (\"ì–´ë–¤ ê°’ì´ ì •ë‹µì´ë‹¤\" í•˜ëŠ” ê°’ì´ ìˆëŠ” ê±´ ì•„ë‹™ë‹ˆë‹¤.)\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” vocab_sizeì™€ embedding_dimì„ 768ë¡œ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "d9723eee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9723eee",
        "outputId": "7e28bd65-d81f-49fa-8278-533f003c8e13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "embedding_vector: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "embedding_vector.weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a9214e",
      "metadata": {
        "id": "98a9214e"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ íŠ¹ì • í† í°ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "8b4c3059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4c3059",
        "outputId": "ee23f9b0-8753-4344-ece4-dd8fa2b4fad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_id: 45\n",
            "input_id ì°¨ì›: torch.Size([1])\n",
            "vector ì°¨ì›: torch.Size([1, 768])\n",
            "vector: tensor([[-5.8641e-01, -1.1327e+00,  2.6612e-02, -3.6936e-01, -4.5574e-01,\n",
            "          1.4395e+00, -2.7049e-01, -2.3921e-02,  4.3165e-01,  6.3602e-01,\n",
            "         -4.0117e-01, -1.0804e+00, -6.4650e-01, -6.8504e-02,  2.4397e-01,\n",
            "         -2.0591e-01, -1.8770e-01,  4.2026e-01,  7.1682e-01, -5.9828e-01,\n",
            "          3.1360e-01,  1.8200e+00,  2.8490e+00,  1.3980e+00,  1.0531e+00,\n",
            "          2.0170e+00,  6.0673e-01, -1.5876e+00,  1.1668e+00, -3.1769e-01,\n",
            "         -5.3360e-01, -4.7004e-01, -9.2409e-01,  1.3773e+00, -1.3743e-01,\n",
            "          4.2839e-02, -4.8446e-01, -9.6651e-01, -1.5018e+00, -4.8411e-01,\n",
            "          1.3622e+00, -1.7072e+00, -7.3317e-01,  2.9438e-01, -1.0314e+00,\n",
            "          1.7281e+00,  1.4170e+00,  1.2014e-01, -1.5709e+00, -3.1901e-01,\n",
            "         -2.0575e-02,  6.4082e-02, -1.9547e-01, -4.9615e-01,  4.1448e-01,\n",
            "         -2.1306e-01, -8.5294e-02,  5.7862e-01,  9.8439e-02,  7.3975e-01,\n",
            "          2.4581e-02,  9.2886e-02, -3.3140e-01, -1.3073e-01,  1.6888e+00,\n",
            "         -1.6246e-01,  3.6534e-01,  1.8052e+00, -5.4247e-01,  1.1382e+00,\n",
            "         -1.1691e-02, -6.5054e-01, -2.9788e+00, -1.7490e+00, -5.2741e-01,\n",
            "         -8.1005e-01,  3.9198e-01,  1.4487e-01,  4.4438e-01, -9.0061e-01,\n",
            "          2.6250e-01, -2.9051e-01,  2.2310e-01, -1.2519e+00,  1.2721e+00,\n",
            "          6.2651e-01,  1.5596e+00, -8.3331e-02, -4.1976e-01,  1.7190e+00,\n",
            "         -8.3126e-01,  1.6253e+00, -2.3224e-01,  8.6379e-01,  6.8156e-01,\n",
            "         -1.7146e+00, -1.4344e-01,  5.6220e-02, -1.8790e+00, -9.5746e-01,\n",
            "          6.4773e-01,  1.7119e-01, -5.1799e-01, -2.9002e-01, -1.4499e+00,\n",
            "         -2.2011e+00, -1.9358e+00,  1.7292e+00,  3.2779e-01,  9.1354e-01,\n",
            "         -1.8337e-01, -1.0150e+00,  6.1067e-02, -1.6252e-01, -1.8904e-01,\n",
            "         -3.1064e-01,  6.4264e-01,  2.4448e+00, -8.2296e-01,  2.3123e-01,\n",
            "          5.2089e-01,  2.2307e-01,  8.9294e-01, -3.4659e-01, -2.2180e+00,\n",
            "         -2.9681e-01,  1.9733e-01,  1.0184e+00, -5.8794e-01,  1.0451e+00,\n",
            "          1.6000e+00,  1.0269e-01, -6.3995e-01,  2.5967e-01, -1.2352e-01,\n",
            "          6.0335e-01, -1.0959e-01,  1.3712e+00,  2.6667e-01, -1.0211e+00,\n",
            "          2.7895e-01, -1.2074e+00, -9.0694e-01,  8.2587e-01,  2.1134e-01,\n",
            "          4.1955e-01, -2.6536e-01, -1.1998e+00,  5.6761e-01,  1.3631e+00,\n",
            "         -1.1470e+00,  2.3841e-01, -1.0672e+00,  1.2854e+00, -2.5034e+00,\n",
            "          1.0756e+00,  7.8051e-02, -1.1610e+00,  2.3808e+00,  5.8393e-03,\n",
            "          1.2712e+00,  6.9454e-01, -2.0363e+00,  4.2008e-01,  1.4959e+00,\n",
            "         -2.6621e+00, -1.1025e+00, -8.7692e-01,  2.7085e-01, -3.6835e-01,\n",
            "         -4.5597e-01,  1.6099e-01,  2.2385e+00,  7.7596e-01,  6.9936e-01,\n",
            "          1.2859e-02, -1.0188e+00,  2.0262e-01,  1.0505e-01, -5.3979e-01,\n",
            "         -1.1471e+00,  1.0325e+00,  2.2522e-01,  1.7243e-01,  8.4644e-01,\n",
            "         -3.9182e-01, -1.3194e+00,  1.9120e+00,  1.1990e+00, -7.1338e-01,\n",
            "         -2.9062e-01, -1.9692e+00, -1.2352e+00,  3.4469e-01,  3.7266e-01,\n",
            "          7.4043e-03,  1.7676e-01,  4.4155e-01, -2.8602e-01,  1.1501e+00,\n",
            "         -4.9747e-01, -2.1877e+00,  1.2597e+00, -4.6811e-01, -1.9778e+00,\n",
            "          9.2266e-02,  8.3967e-01, -1.2875e+00, -4.5443e-01,  8.2618e-01,\n",
            "          1.3657e+00, -1.6183e-01,  2.7951e+00,  5.9410e-01, -8.6167e-01,\n",
            "         -2.4812e+00,  5.2129e-01,  1.0565e+00,  8.2845e-01, -3.9922e-01,\n",
            "          1.6755e+00,  2.2296e+00,  1.4605e+00, -1.3790e+00,  8.9979e-02,\n",
            "         -8.4355e-01, -6.2137e-01,  8.8655e-01, -7.5264e-01,  4.5718e-02,\n",
            "         -8.8061e-01, -1.3311e+00,  2.6024e+00, -8.8568e-02,  3.6131e-01,\n",
            "         -9.6495e-01,  2.5996e-01, -4.8475e-01, -1.1931e+00, -3.5965e-03,\n",
            "          4.5652e-01,  1.1003e+00,  6.0825e-01,  5.0255e-01,  6.4847e-02,\n",
            "         -2.0972e-01, -8.1905e-01,  6.3713e-01,  5.5610e-01, -3.7969e-01,\n",
            "         -8.2476e-01,  3.0568e-01,  1.3790e+00,  1.0315e+00, -1.1049e+00,\n",
            "         -1.2539e+00,  7.8217e-01,  4.2802e-01,  5.2194e-01, -4.2326e-01,\n",
            "          6.9081e-01, -1.1530e+00,  1.0535e+00,  8.4309e-01, -1.5127e+00,\n",
            "          1.5953e+00,  1.5544e+00, -3.3269e-01,  1.8270e+00,  2.3450e-01,\n",
            "         -2.6720e-01, -4.8002e-01, -7.2525e-01, -6.9044e-02,  1.8810e-02,\n",
            "          1.4364e-01, -2.2373e+00,  4.0876e-01, -3.7807e-02, -8.5370e-01,\n",
            "         -1.4437e+00, -1.5806e+00,  1.6538e+00,  6.1369e-01,  5.1194e-01,\n",
            "         -1.4412e+00,  6.9254e-01,  1.6215e+00, -8.9781e-01, -2.6808e-01,\n",
            "          6.8007e-01, -2.5736e+00,  3.0228e-01, -2.1020e-01,  4.0738e-01,\n",
            "         -1.2795e+00, -2.1194e+00, -2.3627e-01,  6.4997e-01,  2.0307e-01,\n",
            "         -4.0661e-01, -9.2588e-01, -6.6186e-01, -9.7114e-01, -1.2413e+00,\n",
            "          1.6439e-01,  1.1636e+00,  3.6198e-01, -1.1532e+00, -1.0988e+00,\n",
            "          5.3209e-01, -8.9032e-01,  1.1218e+00,  5.7064e-01,  7.5646e-01,\n",
            "          1.3166e+00,  1.2176e+00, -5.0478e-01, -6.4268e-01,  2.3216e+00,\n",
            "          1.1027e+00,  2.3127e-01,  4.6957e-01, -6.8633e-01, -1.4759e+00,\n",
            "          1.4607e-01, -8.5485e-01,  5.1082e-01,  2.7225e-01, -1.0504e+00,\n",
            "         -1.8880e+00,  8.0767e-01, -1.0015e+00, -2.9965e-01, -6.4340e-01,\n",
            "         -1.1795e+00,  1.2514e+00, -1.1169e+00, -6.2890e-03, -2.4045e+00,\n",
            "         -1.5852e-01,  7.9345e-01, -2.9591e-01,  8.2604e-01, -3.5559e-01,\n",
            "          1.7587e-01,  1.5028e-01, -2.7314e-01,  3.9683e-02, -1.1727e+00,\n",
            "         -1.7857e+00, -1.6997e+00,  9.1090e-01,  6.2496e-01,  7.2536e-02,\n",
            "         -2.5993e-01, -7.4421e-01, -1.4108e+00,  1.1926e-01,  9.8203e-01,\n",
            "          5.4706e-01,  1.0072e-01, -7.9624e-02,  7.1058e-02,  1.7737e-01,\n",
            "          7.5613e-01, -1.2531e+00,  6.6835e-01, -1.0337e+00, -9.1633e-01,\n",
            "          4.8913e-01, -4.7103e-01, -4.2296e-01, -8.8159e-01, -1.6258e+00,\n",
            "          8.6559e-01,  8.9447e-01,  1.0847e+00,  2.9223e-01,  1.3801e+00,\n",
            "          5.5510e-01,  2.3797e-01,  1.6000e-01, -2.7714e-01, -1.3358e+00,\n",
            "         -1.5762e-01, -1.0363e+00,  9.8573e-01, -1.1911e+00,  2.4253e-01,\n",
            "          5.4839e-01,  1.3786e+00,  1.5118e+00,  2.5880e-01,  1.1013e+00,\n",
            "          1.4151e+00, -1.2057e-01,  1.3439e-01, -1.5628e+00, -6.1287e-01,\n",
            "         -1.1348e+00, -9.6102e-01,  1.7011e+00,  5.0617e-01, -1.9768e+00,\n",
            "         -5.6951e-01,  1.5390e+00,  6.3183e-02, -1.6705e+00,  1.4659e+00,\n",
            "          1.1269e+00, -3.0730e+00, -1.1650e+00,  1.1070e+00,  2.4070e-01,\n",
            "          2.7651e-01, -1.2080e+00,  4.8507e-01,  7.9149e-02,  5.4360e-01,\n",
            "         -8.3520e-01,  9.3864e-01, -8.5778e-01,  3.6294e-01,  1.0618e+00,\n",
            "          1.3808e-01, -3.9061e-02, -3.5348e-01,  2.1225e+00, -7.2674e-01,\n",
            "         -1.7458e+00,  1.0003e+00,  2.8215e-02,  1.1499e+00,  4.2818e-01,\n",
            "          1.5518e+00, -8.6611e-01,  1.4710e+00, -8.2705e-01,  9.8005e-02,\n",
            "          2.6920e+00,  1.3048e+00,  6.0844e-01, -1.2385e+00,  4.6886e-01,\n",
            "         -8.6682e-01,  1.0413e+00, -2.7178e-01,  1.4223e+00,  2.9257e+00,\n",
            "          9.2931e-02,  5.7789e-01, -1.5264e+00,  3.8429e-01,  3.2746e-01,\n",
            "         -1.1850e+00,  1.0487e+00, -1.0260e-01,  5.1305e-01, -4.3763e-01,\n",
            "         -1.1442e+00,  1.6211e-01,  1.0189e-01, -8.6003e-01,  3.7350e-01,\n",
            "         -2.0934e+00,  9.4786e-01,  8.0349e-01,  9.0876e-02, -7.2433e-01,\n",
            "          8.9107e-01,  2.8971e-01,  1.4685e+00, -9.0758e-01,  1.0190e+00,\n",
            "         -1.1583e+00, -1.5949e+00, -2.5171e-01,  2.0537e-01, -1.7279e+00,\n",
            "          2.3990e-01, -2.2937e+00,  6.8148e-01,  1.5945e+00,  4.0917e-01,\n",
            "         -7.5195e-01,  1.1046e-01, -1.5076e+00, -8.0238e-01,  2.2897e-01,\n",
            "          6.2368e-01, -3.0776e-01, -1.5446e-01,  9.0203e-01,  2.1589e+00,\n",
            "          1.4359e-02, -2.0427e-01,  4.5405e-01,  1.6242e+00,  2.4179e+00,\n",
            "          1.9296e-02, -1.0937e+00, -4.3272e-01, -8.0123e-01,  1.6898e-01,\n",
            "         -7.9126e-01, -3.3747e-01, -2.6263e-01,  6.3985e-01,  1.9795e+00,\n",
            "          5.0256e-01,  4.2781e-01,  9.2407e-01, -1.1289e+00,  1.6008e+00,\n",
            "          2.7487e-01,  2.4097e-01,  6.6713e-01, -5.3765e-01, -3.8973e-01,\n",
            "          5.5697e-01,  5.1861e-02, -1.0619e+00, -1.9407e+00, -1.1581e+00,\n",
            "          3.4482e-01, -7.0241e-01,  1.4376e+00, -1.1725e+00, -3.8754e-01,\n",
            "          6.0148e-01, -4.2554e-01, -1.6213e-01,  6.2803e-02,  5.8063e-01,\n",
            "         -3.4327e-01, -4.5692e-01,  9.6038e-01,  6.9764e-01,  1.0929e+00,\n",
            "          1.7693e+00, -3.1421e-02, -1.0884e+00, -1.0127e-01, -1.9810e-01,\n",
            "          4.4012e-02, -1.2764e+00, -1.0442e+00,  4.5751e-01,  3.7497e-01,\n",
            "         -8.9870e-01, -8.6049e-03,  1.6212e+00,  2.1729e-01, -1.3368e+00,\n",
            "         -4.6538e-04,  5.7354e-01, -1.4653e+00,  1.1711e+00,  2.9986e-01,\n",
            "          2.3952e-01, -6.4066e-01,  3.2257e-01, -1.0702e+00, -4.5255e-01,\n",
            "          8.4570e-01,  8.7082e-01, -1.2804e+00, -8.0807e-01, -1.0393e+00,\n",
            "          1.8883e-01,  2.9374e-01,  1.8074e-02,  1.1724e+00, -5.2455e-01,\n",
            "         -4.1127e-01,  6.3151e-01, -3.2293e-01,  1.1213e+00,  8.8539e-01,\n",
            "         -7.4528e-01,  2.5474e+00,  4.3508e-01,  1.5564e-01, -2.8813e-01,\n",
            "         -1.4950e+00,  1.9958e+00, -4.4929e-01,  5.7363e-01,  1.3688e+00,\n",
            "          9.8464e-01, -1.5622e+00,  2.9645e-01,  7.9629e-02, -1.0188e+00,\n",
            "         -2.8821e-01,  6.5786e-01, -9.4752e-01, -6.8457e-02,  5.4615e-01,\n",
            "          3.1922e-01, -9.3858e-01,  2.0790e+00,  2.0641e-01,  1.3692e+00,\n",
            "          3.6679e-01,  1.2206e-01,  3.4521e-01,  2.1476e-01,  9.4113e-01,\n",
            "          9.7986e-01, -1.2927e+00, -4.6423e-01, -2.4949e-01,  1.5714e+00,\n",
            "          6.6313e-01,  4.8623e-01,  7.1229e-02, -1.1668e-01,  1.0935e+00,\n",
            "         -4.1720e-01,  1.2234e-01,  2.5845e-01, -5.0578e-01,  1.6090e+00,\n",
            "          4.8093e-02,  2.7948e-01,  4.5103e-01, -5.2214e-01, -1.2607e+00,\n",
            "         -5.7107e-01, -5.7751e-01,  6.6488e-01, -1.7756e+00,  6.5838e-01,\n",
            "         -2.7618e-01, -1.5014e+00,  5.9242e-01,  1.7892e+00,  1.5430e+00,\n",
            "          2.9727e-01,  1.8970e+00,  2.3541e-01,  7.3836e-01, -2.1829e-01,\n",
            "         -5.6520e-01, -5.2170e-01, -2.8841e-01,  1.7133e+00,  1.3969e-01,\n",
            "         -4.4374e-01, -1.5180e+00,  5.8020e-01, -1.4620e-01, -1.8151e+00,\n",
            "          1.8509e+00, -5.7693e-01,  6.2626e-01, -7.9069e-01, -1.7662e+00,\n",
            "         -7.7322e-01, -1.0780e-01,  8.9673e-01,  2.0367e+00,  6.2815e-01,\n",
            "         -5.8681e-01, -1.0963e+00,  5.1416e-01, -1.6618e+00, -2.3677e-01,\n",
            "          5.0208e-01, -3.8207e-01,  4.7563e-01, -7.4501e-01, -1.4155e-01,\n",
            "         -2.1625e-01, -1.9711e+00, -1.2997e+00,  6.5497e-01, -2.1389e-01,\n",
            "         -1.5022e-01, -4.7207e-01,  1.0380e+00,  1.0139e+00, -1.5492e+00,\n",
            "         -9.2274e-01, -3.6818e-03, -1.9299e+00, -3.1747e-01,  4.3391e-01,\n",
            "          6.2427e-01,  9.4415e-01, -1.2236e+00, -1.2878e-01,  3.8714e-01,\n",
            "          9.4548e-01, -8.0918e-01, -2.0064e+00,  4.8596e-02, -9.9246e-01,\n",
            "          4.3346e-01,  1.9962e-01, -1.0281e+00,  1.2949e+00, -9.7883e-01,\n",
            "          7.2204e-01,  1.6217e-01,  1.1873e+00, -1.6302e+00, -1.6191e-01,\n",
            "          7.4264e-01,  1.2234e-01,  5.3141e-02, -1.7858e+00,  9.8436e-02,\n",
            "         -5.4184e-01,  4.1263e-01,  8.8509e-01, -3.8275e-01, -5.5372e-01,\n",
            "         -1.0093e+00, -1.8745e+00, -3.1291e-02, -6.5305e-01,  9.3340e-01,\n",
            "         -8.9972e-01,  1.0360e+00, -8.8613e-01, -3.8863e-01,  2.2449e-01,\n",
            "         -1.0740e+00,  5.8647e-01, -8.3409e-01, -2.4781e+00, -1.6360e+00,\n",
            "         -1.2667e+00,  1.0647e+00,  6.0862e-01,  1.0411e+00,  4.9001e-01,\n",
            "         -5.6568e-01, -7.7290e-02,  1.6889e+00, -5.3592e-01,  3.0126e-01,\n",
            "         -9.3709e-01, -1.0054e+00,  6.8849e-02,  6.9186e-01, -1.2959e+00,\n",
            "          8.7209e-01,  2.7381e-01,  1.6178e+00,  3.3304e-01,  2.3623e+00,\n",
            "          4.5610e-01, -7.9843e-02, -2.8436e-01, -1.5437e+00, -1.1984e+00,\n",
            "         -7.8466e-01,  1.1022e+00,  1.5757e-01, -1.2095e+00,  2.2163e-01,\n",
            "          6.4150e-01,  1.0414e+00,  8.6908e-01]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "token_id = tokenizer.token_to_id(\"I\")\n",
        "print(\"token_id:\", token_id)\n",
        "input_id = torch.tensor([token_id], dtype=torch.long)\n",
        "print(\"input_id ì°¨ì›:\", input_id.shape)\n",
        "\n",
        "vector = embedding_vector(input_id)\n",
        "print(\"vector ì°¨ì›:\", vector.shape)\n",
        "print(\"vector:\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f47d8d6",
      "metadata": {
        "id": "7f47d8d6"
      },
      "source": [
        "# 2. RNN/LSTM\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. RNN/LSTMì„ ì´ìš©í•˜ì—¬ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•œ ë¬¸ë§¥ ë²¡í„°ì— ëŒ€í•œ ì´í•´ë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
        "  2. Encoder Decoder êµ¬ì¡°ë¥¼ í†µí•´ ë¬¸ë§¥ ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ íŠ¹ì • taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. RNN/LSTM\n",
        "  2. Encoder/Decoder\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. ê°„ë‹¨í•œ RNN/LSTMì„ êµ¬í˜„í•œë‹¤.\n",
        "  2. ë²ˆì—­ taskì™€ ê´€ë ¨ëœ encoder decoder êµ¬ì¡°ë¥¼ êµ¬í˜„í•œë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cfb8ca",
      "metadata": {
        "id": "d6cfb8ca"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ§  Recurrent Neural Network(RNN)ì´ë€? </b><br>\n",
        "ìˆœì°¨ì (Sequential) ì´ì „ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ì—¬ í˜„ì¬ì˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "RNNì´ ê°–ëŠ” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ì…ë ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "- RNNì€ ê°™ì€ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "- ì¬ê·€ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec4dfc5c",
      "metadata": {
        "id": "ec4dfc5c"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ RNNì— ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ ì¶œë ¥ì¸µì˜ ê²°ê³¼ê°’ì„ ë°›ì•„ë´…ì‹œë‹¤!\n",
        "\n",
        "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ë³´ì•˜ë“¯, ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "ì›Œë“œ ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "2b720ce0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b720ce0",
        "outputId": "e090f424-2887-4566-b8b9-e291c96dd399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›Œë“œ ì„ë² ë”© ì°¨ì› : torch.Size([30000, 768])\n"
          ]
        }
      ],
      "source": [
        "word_embeddings: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› :\", word_embeddings.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9be639",
      "metadata": {
        "id": "6f9be639"
      },
      "source": [
        "ì›Œë“œ ì„ë² ë”© ì°¨ì›ì— ë§ê²Œ RNNì„ êµ¬í˜„í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "d6cf6ed2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6cf6ed2",
        "outputId": "46c03c9b-906d-4bd2-8f21-7f18051e625d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h_0ì˜ ì°¨ì› : torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "input_size: int = word_embeddings.weight.size()[1] # RNNì˜ input sizeëŠ” ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "hidden_size: int = 1024  # RNNì˜ hidden size\n",
        "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "rnn = nn.RNN(\n",
        "    input_size=input_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "# ì´ˆê¸° hidden state ì´ˆê¸°í™”\n",
        "\n",
        "hidden_state_shape: int = (num_layers * (2 if bidirectional else 1), hidden_size)\n",
        "\n",
        "h_0: Tensor2D[Sequence, HiddenStates] = torch.zeros(hidden_state_shape)  # (num_layers * num_dirs, hidden_size)\n",
        "print(\"h_0ì˜ ì°¨ì› :\",h_0.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb4f18e",
      "metadata": {
        "id": "cbb4f18e"
      },
      "source": [
        "ì…ë ¥ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”í•œ í›„, idsë§Œ êº¼ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "bcf10c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcf10c34",
        "outputId": "9ca71821-a973-4970-9448-501e32ff9ba6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6227, 7125, 3302, 9046,   18])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "text: str = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
        "\n",
        "# í† í°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "encoded = tokenizer.encode(text)\n",
        "# í† í°ì˜ idsë§Œ êº¼ëƒ…ë‹ˆë‹¤.\n",
        "input_ids: List[int] = encoded.ids\n",
        "\n",
        "# í…ì„œí™”ë¥¼ í•©ë‹ˆë‹¤.\n",
        "input_ids: Tensor1D[Sequence] = torch.tensor(input_ids, dtype=torch.long)\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13935ca0",
      "metadata": {
        "id": "13935ca0"
      },
      "source": [
        "ë³€í™˜ëœ input_idsë¥¼ ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë„£ê³ \n",
        "ì›Œë“œ ì„ë² ë”©ì„ RNNì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ë‘ outputì„ ì–»ìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. `hidden_states`: ê° time stepì— í•´ë‹¹í•˜ëŠ” hidden stateë“¤ì˜ ë¬¶ìŒ.\n",
        "2. `h_n`: ëª¨ë“  sequenceë¥¼ ê±°ì¹˜ê³  ë‚˜ì˜¨ ë§ˆì§€ë§‰ hidden state(`last hidden state`). hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ ë™ì¼."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "97d65561",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d65561",
        "outputId": "635f2287-f6ba-4419-b9df-9725305f5609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›Œë“œ ì„ë² ë”© ì°¨ì› :  torch.Size([5, 768])\n",
            "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
            "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
            "hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "input_embeds: Tensor2D[Sequence, EmbeddingSize] = word_embeddings(input_ids)\n",
        "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› : \", input_embeds.shape)  # (vocab_size, embedding_dim)\n",
        "outputs = rnn(input_embeds, h_0)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
        "\n",
        "# sequence_length: input_tokenì˜ ê¸¸ì´(length), hidden size: hidden state ì°¨ì› ìˆ˜, num_layers: layer ê°œìˆ˜, num_dirs: ë°©í–¥ì˜ ê°œìˆ˜\n",
        "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (sequence_length, d_h)\n",
        "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers * num_dirs, d_h) = (1, d_h)\n",
        "\n",
        "if torch.equal(hidden_states[-1].unsqueeze(0), h_n):\n",
        "    print(\"hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ecc103e",
      "metadata": {
        "id": "7ecc103e"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ì´ëŸ¬í•œ ì€ë‹‰ ìƒíƒœ(hidden state)ë¥¼ ì–»ì–´ì„œ ì–´ë– í•œ ì‘ì—…ì„ í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  ì€ë‹‰ ìƒíƒœ(hidden state)ëŠ” ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ì••ì¶•ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.</b><br>\n",
        "RNN layerë¥¼ í†µê³¼í•˜ë©´ì„œ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•˜ê²Œ ë˜ê³  ì´ëŸ¬í•œ ì •ë³´ë“¤ì€ hidden stateì— ë‹´ê¸°ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ hidden stateëŠ” ë¬¸ë§¥ ë²¡í„°(context vector)ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ë¬¸ë§¥ ë²¡í„°(context vector)ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ë²¡í„°ìƒì— ì••ì¶•í•˜ì—¬ ì €ì¥í•œ ê²ƒìœ¼ë¡œ, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” ë²ˆì—­(translation) taskë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ hidden stateë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë²ˆì—­ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” last hidden stateë¥¼ ë‹¤ì‹œ ì €í¬ì˜ ì…ë ¥ ë°ì´í„°ì™€ ìœ ì‚¬í•œ í˜•íƒœì¸ í…ìŠ¤íŠ¸(í† í°) idë¡œ ë³€í™˜í•˜ëŠ” layerê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ì €í¬ëŠ” Decoderë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/Ssunbell/TIL/refs/heads/master/assets/Seq2SeqRNN.png)\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì•„ë˜ì—ì„œ Encoderì™€ Decoderë¥¼ ì—°ê²°í•˜ì—¬ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë¨¼ì € ì¸ì½”ë”ë¥¼ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ êµ¬í˜„í•œ rnnì„ ê·¸ëŒ€ë¡œ ì´ìš©í•˜ì—¬ í´ë˜ìŠ¤í™”ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "f35ff084",
      "metadata": {
        "id": "f35ff084"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Tuple\n",
        "\n",
        "class Encoder(nn.Module, ABC):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        pass\n",
        "\n",
        "class RNNEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,   # batch_first=False (default)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"ì…ë ¥ í† í°ì„ ì„ë² ë”©í•˜ê³  RNNìœ¼ë¡œ í†µê³¼ì‹œì¼œ ì€ë‹‰ìƒíƒœ ì‹œí€€ìŠ¤ì™€ ë§ˆì§€ë§‰ ì€ë‹‰ìƒíƒœ ë°˜í™˜\"\"\"\n",
        "        # (L, B) -> (L, B, E)\n",
        "        input_embeds = self.word_embeddings(input_ids.long())\n",
        "\n",
        "        # RNN í†µê³¼: output=(L, B, H[*num_dirs]), h_n=(num_layers[*num_dirs], B, H)\n",
        "        hidden_states, h_n = self.rnn(input_embeds)\n",
        "\n",
        "        return hidden_states, h_n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b15bc9",
      "metadata": {
        "id": "61b15bc9"
      },
      "source": [
        "ë‹¤ìŒ ë””ì½”ë” ë¶€ë¶„ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "a5a3b846",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a3b846",
        "outputId": "2f99b584-ee51-4433-a9bf-d8e9d9317095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‚˜ì˜¬ë•Œ ëª»ë³¼ê¸°ë‚˜ ë”°ë¦„ì´ë‹¤ ë‚˜í™€ë¡œì§‘ì—ine ã„ì‚¬ëŒ ì–´ë””ê°€ì„œ ì´ë”°êµ¬\n"
          ]
        }
      ],
      "source": [
        "# ë””ì½”ë” ëª¨ë¸ ë˜í•œ RNNì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "class Decoder(nn.Module, ABC):\n",
        "    def __init__(self: \"Decoder\") -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, input_ids: torch.Tensor, init_hidden_state: torch.Tensor) -> torch.Tensor:\n",
        "        pass\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size,\n",
        "                 num_layers, bidirectional, start_token_id, end_token_id):\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,     # batch_first=False\n",
        "        )\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        init_hidden_state: torch.Tensor,      # (num_layers*num_dirs, B, H)\n",
        "        max_len: int = 10\n",
        "    ) -> Tuple[torch.Tensor, List[int]]:\n",
        "\n",
        "        # --- h_n ì°¨ì› ë³´ì • (í˜¹ì‹œ 2Dë¡œ ë“¤ì–´ì˜¤ë©´ 3Dë¡œ ë³µì›) ---\n",
        "        h_n = init_hidden_state\n",
        "        if h_n.dim() == 2:                    # (B, H) or (H, )\n",
        "            if h_n.ndim == 2:                 # (B, H) -> (1, B, H)\n",
        "                h_n = h_n.unsqueeze(0)\n",
        "            else:\n",
        "                raise RuntimeError(\"init_hidden_state shape is invalid.\")\n",
        "\n",
        "        B = h_n.size(1)                       # ë°°ì¹˜ í¬ê¸° (ì—¬ê¸°ì„  1 ê°€ì •)\n",
        "        device = h_n.device\n",
        "\n",
        "        logits_list: List[torch.Tensor] = []\n",
        "        # ì‹œì‘ í† í° (B=1 ê°€ì •)\n",
        "        input_token = torch.tensor([self.start_token_id], dtype=torch.long, device=device)\n",
        "        output_token_ids: List[int] = [input_token.item()]\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token.item() == self.end_token_id:\n",
        "                break\n",
        "\n",
        "            # (L=1, B=1) â†’ ì„ë² ë”© (1,1,E)\n",
        "            emb = self.word_embeddings(input_token).unsqueeze(0)  # [1, 1, E]\n",
        "\n",
        "            # RNN í†µê³¼: output=(1,1,H), h_n=(num_layers[*dirs],1,H)\n",
        "            output, h_n = self.rnn(emb, h_n)\n",
        "\n",
        "            # ë¡œì§“ ê³„ì‚°ì€ ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì€ë‹‰ìƒíƒœ ì‚¬ìš© (shape ìœ ì§€ ì£¼ì˜!)\n",
        "            last_h = h_n[-1, 0, :]            # [H]  â† ì—¬ê¸°ì„œë§Œ 1Dë¡œ êº¼ëƒ„\n",
        "            logit = self.fully_connected_layer(last_h)  # [V]\n",
        "            logits_list.append(logit)\n",
        "\n",
        "            # ë‹¤ìŒ ì…ë ¥ í† í° (greedy)\n",
        "            input_token = torch.argmax(logit, dim=-1).unsqueeze(0)  # [1]\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        logits = torch.stack(logits_list, dim=0)  # (T, V)\n",
        "        return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024  # RNNì˜ hidden size\n",
        "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "rnn_decoder = RNNDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "logits, output_token_ids = rnn_decoder(h_n)\n",
        "output_texts = tokenizer.decode(output_token_ids)\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a43d683",
      "metadata": {
        "id": "2a43d683"
      },
      "source": [
        "ì´ì œ êµ¬í˜„í•œ encoderì™€ decoderë¥¼ ì—°ê²°í•˜ì—¬ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "55b85dfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b85dfe",
        "outputId": "6d463cd9-ee14-411e-8a06-f41d6289f036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‚˜ì˜¬ë•Œ ëª»ë³¼ê¸°ë‚˜ ë”°ë¦„ì´ë‹¤ ë‚˜í™€ë¡œì§‘ì—ine ã„ì‚¬ëŒ ì–´ë””ê°€ì„œ ì´ë”°êµ¬\n"
          ]
        }
      ],
      "source": [
        "class RNNSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"RNNSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"RNNSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, context_vector = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(context_vector)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = RNNSeq2Seq(rnn_encoder, rnn_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e7487e",
      "metadata": {
        "id": "36e7487e"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ¤” ê²°ê³¼ê°’ì´ ì´ìƒí•´ìš”</b><br>\n",
        "ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµì„ í•˜ì§€ ì•Šì•„ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì˜ êµ¬ì¡°ì— ëŒ€í•´ì„œ ì§‘ì¤‘í•˜ê³  ì¶”í›„ì— ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ê²½í—˜í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì €í¬ëŠ” Sequence to Sequence(Encoder - Decoder) êµ¬ì¡°ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
        "\n",
        "Seq2Seq êµ¬ì¡° ë‚´ì—ì„œ ì‹¤ì œ ì›Œë“œ ì„ë² ë”©ì„ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , ê·¸ ë³€í™˜ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ í…ìŠ¤íŠ¸(í† í°)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì“°ì¸ ëª¨ë¸ì€ RNNì´ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "RNNë¿ë§Œ ì•„ë‹ˆë¼ LSTM, ì–´í…ì…˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ Seq2Seq êµ¬ì¡°ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì „ì²´ì ì¸ í° í‹€ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ì±„, RNN ëª¨ë“ˆë§Œ ë°”ê¿”ì£¼ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° LSTMìœ¼ë¡œ ë‹¤ì‹œ í•œë²ˆ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8758c710",
      "metadata": {
        "id": "8758c710"
      },
      "source": [
        "RNNê³¼ LSTMì˜ ê°€ì¥ í° ì°¨ì´ì ì€ LSTMì—ëŠ” cell stateê°€ ì¶”ê°€ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¥ê¸° ê¸°ì–µì„ ë‹´ë‹¹í•˜ëŠ” cell stateë¥¼ í†µí•´ ì¢€ë” ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  Key point!</b><br>\n",
        "ëª¨ë¸ì˜ ì•„í‚¤í…ì³ë§ˆë‹¤ ëª¨ë¸ì˜ ì…ì¶œë ¥ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ì–´ë–»ê²Œ ë‚˜ì˜¤ëŠ”ì§€ì— ëŒ€í•´ì„œ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ê·¸ëŸ¬ë©´ Encoderì—ì„œ LSTMì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "bf861480",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf861480",
        "outputId": "825a6ef0-c3e1-4569-dfec-cf36459d885c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
            "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
            "c_n ì°¨ì› :  torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "class LSTMEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,   # batch_first=False (ê¸°ë³¸)\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor   # ê¸°ëŒ€ í˜•íƒœ: (L, B)\n",
        "    ) -> Tuple[\n",
        "        torch.Tensor,             # hidden_states: (L, B, H * num_dirs)\n",
        "        Tuple[torch.Tensor, torch.Tensor]  # (h_n, c_n): (num_layers*num_dirs, B, H)\n",
        "    ]:\n",
        "        # (L, B) -> (L, B, E)\n",
        "        input_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        # output: (L, B, H*num_dirs)\n",
        "        # h_n: (num_layers*num_dirs, B, H)\n",
        "        # c_n: (num_layers*num_dirs, B, H)\n",
        "        hidden_states, (h_n, c_n) = self.lstm(input_embeds)\n",
        "\n",
        "        # TODO ì±„ì›€ ì™„ë£Œ\n",
        "        # hidden_states: Tensor2D[Sequence, HiddenStates]\n",
        "        # h_n: Tensor2D[Layers, HiddenStates]\n",
        "        # c_n: Tensor2D[Layers, HiddenStates]\n",
        "        return hidden_states, (h_n, c_n)\n",
        "vocab_size = 30000\n",
        "embedding_dim = 768\n",
        "hidden_size = 1024  # RNNì˜ hidden size\n",
        "num_layers = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "lstm_encoder = LSTMEncoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "outputs = lstm_encoder(input_ids)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (L, B, d_h)\n",
        "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
        "print(\"c_n ì°¨ì› : \", c_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d7ab4d",
      "metadata": {
        "id": "40d7ab4d"
      },
      "source": [
        "ì´ë²ˆì—ëŠ” LSTMì„ ì‚¬ìš©í•˜ì—¬ Decoder Layerë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "77ba9e94",
      "metadata": {
        "id": "77ba9e94",
        "outputId": "e6713b4f-accf-4c7d-e7bb-40fd04fe52e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ìƒì— í›„íšŒ ì•„ì´ëŒì´ í¬ë¥´ë…¸ë¥¼ ì˜¬ë¦¬ ì¡°ë”” êº™ ë‹´ê¸´ ìš”ê°€ë§Œí•˜ë©´\n"
          ]
        }
      ],
      "source": [
        "class LSTMDecoder(Decoder):\n",
        "    def __init__(\n",
        "        self: \"LSTMDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self: \"LSTMDecoder\",\n",
        "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
        "        init_cell_state: Tensor2D[Layers, HiddenStates],\n",
        "        max_len: int = 10\n",
        "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "                break\n",
        "\n",
        "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
        "\n",
        "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        \"\"\"ë¦¬ìŠ¤íŠ¸ì˜ logitsë¥¼ torchì˜ Tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\"\"\"\n",
        "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNNì˜ hidden size\n",
        "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "lstm_decoder = LSTMDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = lstm_decoder(h_n, c_n)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c8db0e2",
      "metadata": {
        "id": "8c8db0e2"
      },
      "source": [
        "Encoderì™€ Decoderë¥¼ ì‚¬ìš©í•˜ì—¬ Seq2Seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "fddfe053",
      "metadata": {
        "id": "fddfe053",
        "outputId": "0f1ec9f4-6f2f-4316-da3a-767c59a741b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ìƒì— í›„íšŒ ì•„ì´ëŒì´ í¬ë¥´ë…¸ë¥¼ ì˜¬ë¦¬ ì¡°ë”” êº™ ë‹´ê¸´ ìš”ê°€ë§Œí•˜ë©´\n"
          ]
        }
      ],
      "source": [
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"LSTMSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"LSTMSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (context_vector, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(context_vector, cell_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = LSTMSeq2Seq(lstm_encoder, lstm_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0391cd8a",
      "metadata": {
        "id": "0391cd8a"
      },
      "source": [
        "# 3. Attention Mechanism\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. Luong Attention(Dot Attention)ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
        "  2. Attentionì„ ì´ìš©í•˜ì—¬ Decoderë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. Luong Attention\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. Luong Attentionì„ êµ¬í˜„í•œë‹¤.\n",
        "  2. Seq2Seq êµ¬ì¡°ì— ë“¤ì–´ê°ˆ Decoderë¥¼ êµ¬í˜„í•œë‹¤.\n",
        "\n",
        "\n",
        "ì´ë²ˆì—ëŠ” Attentionì„ ì‚¬ìš©í•œ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  Attention Mechanism</b><br>\n",
        "í˜„ì¬ êµ¬í˜„í•  seq2seq ëª¨ë¸ì—ì„œì˜ Attentionì€ ìµœê·¼ ì‚¬ìš©í•˜ëŠ” attentionì€ ì•„ë‹™ë‹ˆë‹¤. ìµœê·¼ì˜ Transformers ëª¨ë¸ë“¤ì€ Multi-Head Scaled Dot-Product Attentionì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ê³¼ì œì—ì„œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "1. ì „ì²´ì ì¸ Seq2Seq ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ë™ì¼í•©ë‹ˆë‹¤.\n",
        "2. Encoderì—ì„œ context vectorë¥¼ ì–»ì„ ë•Œ, LSTMì„ ì‚¬ìš©í•˜ëŠ” Encoder ëª¨ë“ˆì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "3. Decoderì—ì„œ output tokenì„ ìƒì„±í•  ë•Œ, attention mechanismì„ ì¶”ê°€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3807ee",
      "metadata": {
        "id": "ad3807ee"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ìš°ì„  Dot Attention(Luong attention)ì„ ë¨¼ì € êµ¬í˜„í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "70059257",
      "metadata": {
        "id": "70059257"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self: \"LuongAttention\", hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.W_a = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°í•˜ì„¸ìš”\n",
        "    def forward(\n",
        "        self:\"LuongAttention\",\n",
        "        h_t: torch.Tensor,                 # (H,)\n",
        "        encoder_outputs: torch.Tensor,     # (L, H)\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"1) ì¿¼ë¦¬(ht)ë¥¼ ì„ í˜•ë³€í™˜\"\"\"\n",
        "        Wa_ht = self.W_a(h_t)              # (H,)\n",
        "\n",
        "        \"\"\"2) ì ìˆ˜: ê° íƒ€ì„ìŠ¤í…ì˜ enc_hiddenê³¼ Wa_ht ë‚´ì  â†’ (L,)\"\"\"\n",
        "        attention_score = encoder_outputs @ Wa_ht  # (L,)\n",
        "\n",
        "        \"\"\"3) ì •ê·œí™”(softmax) â†’ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ (L,)\"\"\"\n",
        "        attention_weights = F.softmax(attention_score, dim=0)  # (L,)\n",
        "\n",
        "        \"\"\"4) ì»¨í…ìŠ¤íŠ¸: ê°€ì¤‘í•© Î£ a_t * h_enc_t â†’ (H,)\"\"\"\n",
        "        context_vector = (attention_weights.unsqueeze(1) * encoder_outputs).sum(dim=0)  # (H,)\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df83103d",
      "metadata": {
        "id": "df83103d"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ¤” ì—‡ ì—¬ê¸°ì„œë„ context vectorê°€ ë‚˜ì˜¤ë„¤ìš”?</b><br>\n",
        "ë„¤ ê·¸ë ‡ìŠµë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” encoderì˜ ë§ˆì§€ë§‰ hidden state(h_n)ì„ context vectorë¼ê³  ë¶ˆë €ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, attentionì´ ë‚˜ì˜¤ë©´ì„œ context vectorëŠ” ê° ë””ì½”ë”© ì‹œì ë§ˆë‹¤ ì¸ì½”ë”ì˜ ëª¨ë“  hidden statesì— ëŒ€í•œ ì–´í…ì…˜ ê°€ì¤‘í•©ì´ë¼ê³  ìƒê°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "êµ¬í˜„í•œ attention mechanismì„ ì´ìš©í•˜ì—¬ Decoder layerì— ì ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "e2abb3bc",
      "metadata": {
        "id": "e2abb3bc",
        "outputId": "8404848d-230b-4192-9c09-577ce30b06ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ê¾€ì¤¸ht ì£¼êµ¬ ì œì£¼ ì œì£¼ ì œì£¼ ì œì£¼ í™©ë‹¹í•˜ë‹¤ì“°ë ˆê¸°ì˜í™”\n"
          ]
        }
      ],
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self: \"AttentionDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "        \"\"\"attentionì„ ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
        "        self.attn = LuongAttention(hidden_size)\n",
        "        \"\"\"context vectorì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” trainable weights\"\"\"\n",
        "        self.W_c = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°\n",
        "    def forward(\n",
        "        self:\"AttentionDecoder\",\n",
        "        init_hidden_state: Tensor1D[HiddenStates],\n",
        "        init_cell_state: Tensor1D[HiddenStates],\n",
        "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
        "        max_len: int = 10,\n",
        "    ):\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "                break\n",
        "\n",
        "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
        "\n",
        "            # ì–´í…ì…˜\n",
        "            context_vector, attention_weights = self.attn(concat_h_n, encoder_outputs)\n",
        "\n",
        "            \"\"\"h_n(ì€ë‹‰ ìƒíƒœ)ì™€ context_vectorë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. (Concatenate)\"\"\"\n",
        "            v_t: Tensor1D[HiddenStates * 2] = torch.cat([concat_h_n, context_vector], dim=-1)\n",
        "\n",
        "            \"\"\"v_të¥¼ trainable weightsë¥¼ í†µê³¼ì‹œí‚¤ê³  tanhë¥¼ ì ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
        "            # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "            attentional_hidden_state: Tensor1D[HiddenStates] = torch.tanh(self.W_c(v_t))\n",
        "\n",
        "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(attentional_hidden_state)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        logits = torch.stack(logits, dim=0) if logits else torch.empty(0, self.out.out_features)\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNNì˜ hidden size\n",
        "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "attention_decoder = AttentionDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = attention_decoder(h_n, c_n, hidden_states)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd266f15",
      "metadata": {
        "id": "bd266f15"
      },
      "source": [
        "Decoder layerë¥¼ êµ¬í˜„í–ˆìœ¼ë‹ˆ ì´ì œ Seq2Seq ëª¨ë¸ì— ì ìš©í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "036db196",
      "metadata": {
        "id": "036db196",
        "outputId": "57ae95c0-95b3-4a7e-9a27-d4daaf224f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ê¾€ì¤¸ht ì£¼êµ¬ ì œì£¼ ì œì£¼ ì œì£¼ ì œì£¼ í™©ë‹¹í•˜ë‹¤ì“°ë ˆê¸°ì˜í™”\n"
          ]
        }
      ],
      "source": [
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"AttentionSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"AttentionSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (last_hidden_state, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ h_nì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(last_hidden_state, cell_states, hidden_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = AttentionSeq2Seq(lstm_encoder, attention_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7438c86",
      "metadata": {
        "id": "a7438c86"
      },
      "source": [
        "# 4. Huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n",
        "  2. ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. huggingface\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. HuggingFace Hubì—ì„œ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ì„ ìœ„í•´ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ(from_pretrained)ë¥¼ ì™„ì„±\n",
        "  2. ë¶ˆëŸ¬ì˜¨ í† í¬ë‚˜ì´ì €ë¡œ ì…ë ¥ ë¬¸ì¥ì„ ì¸ì½”ë”©í•˜ê³ , model.generate() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë²ˆì—­ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ ì™„ì„±\n",
        "  3. ê³¼ì œ 2ì—ì„œ ì‚¬ìš©í•œ ë²ˆì—­ ëª¨ë¸ì´ ì‹¤ì œë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ëª¨ë‘ ê°€ì§€ê³  ìˆëŠ”ì§€ ì½”ë“œë¡œ í™•ì¸\n",
        "\n",
        "huggingfaceëŠ” ê¸€ë¡œë²Œ ìµœëŒ€ AI ëª¨ë¸ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì…ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ë§Œ ìˆì—ˆì§€ë§Œ, ìµœê·¼ì—ëŠ” ë¹„ì „, ë¡œë´‡ ë“± ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë“¤ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ Seq2Seq ì•„í‚¤í…ì³ êµ¬ì¡°ì—ì„œ ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87698cfe",
      "metadata": {
        "id": "87698cfe"
      },
      "source": [
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "28f35c6a",
      "metadata": {
        "id": "28f35c6a",
        "outputId": "cc5ddb19-62a2-4c4b-8900-89cc1383a7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d16c583",
      "metadata": {
        "id": "1d16c583"
      },
      "source": [
        "ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì´ Encoderì™€ Decoder ëª¨ë“ˆì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” 2ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. `print(model)`ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œ ì˜ ì •ëˆëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "2. `model.named_parameters()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ í´ë˜ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "f818e2ea",
      "metadata": {
        "id": "f818e2ea",
        "outputId": "327e381b-a9af-4839-8270-da30db5bb59a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MarianMTModel(\n",
            "  (model): MarianModel(\n",
            "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
            "    (encoder): MarianEncoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianEncoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): SiLU()\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): MarianDecoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianDecoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (activation_fn): SiLU()\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "bbaf7975",
      "metadata": {
        "id": "bbaf7975",
        "outputId": "b2b412df-d0d8-434f-e39e-515cfce5ea04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.shared.weight\n",
            "model.encoder.embed_positions.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.bias\n",
            "model.encoder.layers.0.self_attn.v_proj.weight\n",
            "model.encoder.layers.0.self_attn.v_proj.bias\n",
            "model.encoder.layers.0.self_attn.q_proj.weight\n",
            "model.encoder.layers.0.self_attn.q_proj.bias\n",
            "model.encoder.layers.0.self_attn.out_proj.weight\n",
            "model.encoder.layers.0.self_attn.out_proj.bias\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias\n",
            "model.encoder.layers.0.fc1.weight\n",
            "model.encoder.layers.0.fc1.bias\n",
            "model.encoder.layers.0.fc2.weight\n",
            "model.encoder.layers.0.fc2.bias\n",
            "model.encoder.layers.0.final_layer_norm.weight\n",
            "model.encoder.layers.0.final_layer_norm.bias\n",
            "model.encoder.layers.1.self_attn.k_proj.weight\n",
            "model.encoder.layers.1.self_attn.k_proj.bias\n",
            "model.encoder.layers.1.self_attn.v_proj.weight\n",
            "model.encoder.layers.1.self_attn.v_proj.bias\n",
            "model.encoder.layers.1.self_attn.q_proj.weight\n",
            "model.encoder.layers.1.self_attn.q_proj.bias\n",
            "model.encoder.layers.1.self_attn.out_proj.weight\n",
            "model.encoder.layers.1.self_attn.out_proj.bias\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias\n",
            "model.encoder.layers.1.fc1.weight\n",
            "model.encoder.layers.1.fc1.bias\n",
            "model.encoder.layers.1.fc2.weight\n",
            "model.encoder.layers.1.fc2.bias\n",
            "model.encoder.layers.1.final_layer_norm.weight\n",
            "model.encoder.layers.1.final_layer_norm.bias\n",
            "model.encoder.layers.2.self_attn.k_proj.weight\n",
            "model.encoder.layers.2.self_attn.k_proj.bias\n",
            "model.encoder.layers.2.self_attn.v_proj.weight\n",
            "model.encoder.layers.2.self_attn.v_proj.bias\n",
            "model.encoder.layers.2.self_attn.q_proj.weight\n",
            "model.encoder.layers.2.self_attn.q_proj.bias\n",
            "model.encoder.layers.2.self_attn.out_proj.weight\n",
            "model.encoder.layers.2.self_attn.out_proj.bias\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias\n",
            "model.encoder.layers.2.fc1.weight\n",
            "model.encoder.layers.2.fc1.bias\n",
            "model.encoder.layers.2.fc2.weight\n",
            "model.encoder.layers.2.fc2.bias\n",
            "model.encoder.layers.2.final_layer_norm.weight\n",
            "model.encoder.layers.2.final_layer_norm.bias\n",
            "model.encoder.layers.3.self_attn.k_proj.weight\n",
            "model.encoder.layers.3.self_attn.k_proj.bias\n",
            "model.encoder.layers.3.self_attn.v_proj.weight\n",
            "model.encoder.layers.3.self_attn.v_proj.bias\n",
            "model.encoder.layers.3.self_attn.q_proj.weight\n",
            "model.encoder.layers.3.self_attn.q_proj.bias\n",
            "model.encoder.layers.3.self_attn.out_proj.weight\n",
            "model.encoder.layers.3.self_attn.out_proj.bias\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias\n",
            "model.encoder.layers.3.fc1.weight\n",
            "model.encoder.layers.3.fc1.bias\n",
            "model.encoder.layers.3.fc2.weight\n",
            "model.encoder.layers.3.fc2.bias\n",
            "model.encoder.layers.3.final_layer_norm.weight\n",
            "model.encoder.layers.3.final_layer_norm.bias\n",
            "model.encoder.layers.4.self_attn.k_proj.weight\n",
            "model.encoder.layers.4.self_attn.k_proj.bias\n",
            "model.encoder.layers.4.self_attn.v_proj.weight\n",
            "model.encoder.layers.4.self_attn.v_proj.bias\n",
            "model.encoder.layers.4.self_attn.q_proj.weight\n",
            "model.encoder.layers.4.self_attn.q_proj.bias\n",
            "model.encoder.layers.4.self_attn.out_proj.weight\n",
            "model.encoder.layers.4.self_attn.out_proj.bias\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias\n",
            "model.encoder.layers.4.fc1.weight\n",
            "model.encoder.layers.4.fc1.bias\n",
            "model.encoder.layers.4.fc2.weight\n",
            "model.encoder.layers.4.fc2.bias\n",
            "model.encoder.layers.4.final_layer_norm.weight\n",
            "model.encoder.layers.4.final_layer_norm.bias\n",
            "model.encoder.layers.5.self_attn.k_proj.weight\n",
            "model.encoder.layers.5.self_attn.k_proj.bias\n",
            "model.encoder.layers.5.self_attn.v_proj.weight\n",
            "model.encoder.layers.5.self_attn.v_proj.bias\n",
            "model.encoder.layers.5.self_attn.q_proj.weight\n",
            "model.encoder.layers.5.self_attn.q_proj.bias\n",
            "model.encoder.layers.5.self_attn.out_proj.weight\n",
            "model.encoder.layers.5.self_attn.out_proj.bias\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias\n",
            "model.encoder.layers.5.fc1.weight\n",
            "model.encoder.layers.5.fc1.bias\n",
            "model.encoder.layers.5.fc2.weight\n",
            "model.encoder.layers.5.fc2.bias\n",
            "model.encoder.layers.5.final_layer_norm.weight\n",
            "model.encoder.layers.5.final_layer_norm.bias\n",
            "model.decoder.embed_positions.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.bias\n",
            "model.decoder.layers.0.self_attn.v_proj.weight\n",
            "model.decoder.layers.0.self_attn.v_proj.bias\n",
            "model.decoder.layers.0.self_attn.q_proj.weight\n",
            "model.decoder.layers.0.self_attn.q_proj.bias\n",
            "model.decoder.layers.0.self_attn.out_proj.weight\n",
            "model.decoder.layers.0.self_attn.out_proj.bias\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.0.fc1.weight\n",
            "model.decoder.layers.0.fc1.bias\n",
            "model.decoder.layers.0.fc2.weight\n",
            "model.decoder.layers.0.fc2.bias\n",
            "model.decoder.layers.0.final_layer_norm.weight\n",
            "model.decoder.layers.0.final_layer_norm.bias\n",
            "model.decoder.layers.1.self_attn.k_proj.weight\n",
            "model.decoder.layers.1.self_attn.k_proj.bias\n",
            "model.decoder.layers.1.self_attn.v_proj.weight\n",
            "model.decoder.layers.1.self_attn.v_proj.bias\n",
            "model.decoder.layers.1.self_attn.q_proj.weight\n",
            "model.decoder.layers.1.self_attn.q_proj.bias\n",
            "model.decoder.layers.1.self_attn.out_proj.weight\n",
            "model.decoder.layers.1.self_attn.out_proj.bias\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.1.fc1.weight\n",
            "model.decoder.layers.1.fc1.bias\n",
            "model.decoder.layers.1.fc2.weight\n",
            "model.decoder.layers.1.fc2.bias\n",
            "model.decoder.layers.1.final_layer_norm.weight\n",
            "model.decoder.layers.1.final_layer_norm.bias\n",
            "model.decoder.layers.2.self_attn.k_proj.weight\n",
            "model.decoder.layers.2.self_attn.k_proj.bias\n",
            "model.decoder.layers.2.self_attn.v_proj.weight\n",
            "model.decoder.layers.2.self_attn.v_proj.bias\n",
            "model.decoder.layers.2.self_attn.q_proj.weight\n",
            "model.decoder.layers.2.self_attn.q_proj.bias\n",
            "model.decoder.layers.2.self_attn.out_proj.weight\n",
            "model.decoder.layers.2.self_attn.out_proj.bias\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.2.fc1.weight\n",
            "model.decoder.layers.2.fc1.bias\n",
            "model.decoder.layers.2.fc2.weight\n",
            "model.decoder.layers.2.fc2.bias\n",
            "model.decoder.layers.2.final_layer_norm.weight\n",
            "model.decoder.layers.2.final_layer_norm.bias\n",
            "model.decoder.layers.3.self_attn.k_proj.weight\n",
            "model.decoder.layers.3.self_attn.k_proj.bias\n",
            "model.decoder.layers.3.self_attn.v_proj.weight\n",
            "model.decoder.layers.3.self_attn.v_proj.bias\n",
            "model.decoder.layers.3.self_attn.q_proj.weight\n",
            "model.decoder.layers.3.self_attn.q_proj.bias\n",
            "model.decoder.layers.3.self_attn.out_proj.weight\n",
            "model.decoder.layers.3.self_attn.out_proj.bias\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.3.fc1.weight\n",
            "model.decoder.layers.3.fc1.bias\n",
            "model.decoder.layers.3.fc2.weight\n",
            "model.decoder.layers.3.fc2.bias\n",
            "model.decoder.layers.3.final_layer_norm.weight\n",
            "model.decoder.layers.3.final_layer_norm.bias\n",
            "model.decoder.layers.4.self_attn.k_proj.weight\n",
            "model.decoder.layers.4.self_attn.k_proj.bias\n",
            "model.decoder.layers.4.self_attn.v_proj.weight\n",
            "model.decoder.layers.4.self_attn.v_proj.bias\n",
            "model.decoder.layers.4.self_attn.q_proj.weight\n",
            "model.decoder.layers.4.self_attn.q_proj.bias\n",
            "model.decoder.layers.4.self_attn.out_proj.weight\n",
            "model.decoder.layers.4.self_attn.out_proj.bias\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.4.fc1.weight\n",
            "model.decoder.layers.4.fc1.bias\n",
            "model.decoder.layers.4.fc2.weight\n",
            "model.decoder.layers.4.fc2.bias\n",
            "model.decoder.layers.4.final_layer_norm.weight\n",
            "model.decoder.layers.4.final_layer_norm.bias\n",
            "model.decoder.layers.5.self_attn.k_proj.weight\n",
            "model.decoder.layers.5.self_attn.k_proj.bias\n",
            "model.decoder.layers.5.self_attn.v_proj.weight\n",
            "model.decoder.layers.5.self_attn.v_proj.bias\n",
            "model.decoder.layers.5.self_attn.q_proj.weight\n",
            "model.decoder.layers.5.self_attn.q_proj.bias\n",
            "model.decoder.layers.5.self_attn.out_proj.weight\n",
            "model.decoder.layers.5.self_attn.out_proj.bias\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.5.fc1.weight\n",
            "model.decoder.layers.5.fc1.bias\n",
            "model.decoder.layers.5.fc2.weight\n",
            "model.decoder.layers.5.fc2.bias\n",
            "model.decoder.layers.5.final_layer_norm.weight\n",
            "model.decoder.layers.5.final_layer_norm.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167a381f",
      "metadata": {
        "id": "167a381f"
      },
      "source": [
        "ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "ìœ„ì˜ ì‹¤ìŠµì—ì„œ ì¶”ë¡ í–ˆë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥´ê²Œ í•™ìŠµëœ ëª¨ë¸ì´ë¯€ë¡œ ì„±ëŠ¥ì´ ë” ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "7f0ec813",
      "metadata": {
        "id": "7f0ec813",
        "outputId": "0c214702-f4c9-4067-de7e-7e4969b0c064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\n",
            "MT : I'm going to school.\n"
          ]
        }
      ],
      "source": [
        "text = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
        "\"\"\"ì—¬ê¸°ì„œëŠ” batchë¡œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ì°¨ì›ì´ [seq_len]ì´ ì•„ë‹Œ [batch_size, seq_len]ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì…ë ¥ì´ í•œê°œì´ë¯€ë¡œ [1, seq_len]ì…ë‹ˆë‹¤.\"\"\"\n",
        "encoded = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **encoded,\n",
        "    max_new_tokens=64,\n",
        ")\n",
        "\n",
        "translation = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(\"SRC:\", text)\n",
        "print(\"MT :\", translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0383cf9c",
      "metadata": {
        "id": "0383cf9c"
      },
      "source": [
        "# 5. ì•„í‚¤í…ì²˜ë³„ ëª¨ë¸ ë‹¤ë¤„ë³´ê¸°(Encoder model, Decoder model)\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ì˜ ëª¨ë¸ì„ ë‹¤ë£° ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. huggingface\n",
        "- í•™ìŠµ ë‚´ìš©\n",
        "  1. ë¬¸ë§¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ê°•ì ì´ ìˆëŠ” BERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ë¹ˆì¹¸([MASK])ì— ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì¶”ë¡ \n",
        "  2. ì´ì „ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° íŠ¹í™”ëœ GPT-2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ì•¼ê¸°ì˜ ë’·ë¶€ë¶„ì„ ì°½ì‘\n",
        "\n",
        "ì§€ê¸ˆê¹Œì§€ëŠ” Seq2Seq(Encoder - Decoder) ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì€ Only Decoder ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "1. Only Encoder ëª¨ë¸ : BERT ê°™ì€ ëª¨ë¸. RAGë“± ë¬¸ì„œ ê²€ìƒ‰ì— ì£¼ë¡œ ì‚¬ìš©\n",
        "2. Only Decoder ëª¨ë¸ : Chat-GPT ê°™ì€ ëª¨ë¸. ëŒ€í™”, ë²ˆì—­, ì±—ë´‡ ë“± í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©\n",
        "3. Encoder - Decoder ëª¨ë¸ : ìµœê·¼ì—ëŠ” ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ\n",
        "\n",
        "ê·¸ëŸ¬ë©´ Only Encoder ëª¨ë¸ê³¼ Only Decoder ëª¨ë¸ì„ ì´ìš©í•´ ëª¨ë¸ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8039a153",
      "metadata": {
        "id": "8039a153"
      },
      "source": [
        "Encoderì˜ ëŒ€í‘œ ëª¨ë¸ì¸ BERT ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "3ddc1fad",
      "metadata": {
        "id": "3ddc1fad",
        "outputId": "9e53839a-50b6-45be-fda8-897132cd1b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4665108b",
      "metadata": {
        "id": "4665108b"
      },
      "source": [
        "BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(Masked Language Modeling)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, I [MASK] to school. ì´ë¼ëŠ” ë¬¸ì¥ì—ì„œ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¥¼ ë§ì¶˜ë‹¤ê³  í•˜ë©´ I go to school. ì´ ë¬¸ì¥ì´ ì •ë‹µì´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ, I went to schoolë„ ì •ë‹µì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì²˜ëŸ¼ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ëŠ” ì—¬ëŸ¬ê°€ì§€ê°€ ë  ìˆ˜ ìˆê³ , ëª¨ë¸ì˜ í•™ìŠµì— ë”°ë¼ ì–´ë–¤ ë‹¨ì–´ê°€ [MASK]ì— ë“¤ì–´ê°ˆì§€ ê²°ì •ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ëŸ¬í•œ íŠ¹ì„±ì„ ì´ìš©í•˜ì—¬ BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(`[MASK]`)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "4ce98fb7",
      "metadata": {
        "id": "4ce98fb7",
        "outputId": "503a22fe-8442-4419-aa5e-cdda0556b1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›ë³¸ ë¬¸ì¥: I [MASK] to school.\n",
            "BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\n",
            "1ìˆœìœ„: I went to school.\n",
            "2ìˆœìœ„: I go to school.\n",
            "3ìˆœìœ„: I walked to school.\n",
            "4ìˆœìœ„: I ran to school.\n",
            "5ìˆœìœ„: I got to school.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from typing import List, Tuple\n",
        "\n",
        "# 4. ìš°ë¦¬ê°€ ë§ì¶œ ë¬¸ì¥ ë§Œë“¤ê¸°. tokenizer.mask_token = \"[MASK]\" ì´ ë¶€ë¶„ì´ ë¹ˆì¹¸ì´ ë¨\n",
        "sentence = f\"I {tokenizer.mask_token} to school.\"\n",
        "\n",
        "top_k = 5  # ìƒìœ„ 5ê°œ í›„ë³´\n",
        "\n",
        "# 5. ë¬¸ì¥ì„ ìˆ«ìë¡œ ë³€í™˜\n",
        "encoded = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True)\n",
        "\n",
        "# 6. ì…ë ¥ í† í° ID\n",
        "input_ids = encoded.input_ids\n",
        "\n",
        "# 7. [MASK] í† í° ID\n",
        "mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "# 8. [MASK] ìœ„ì¹˜ ì°¾ê¸° (ë°°ì¹˜, í† í°ìœ„ì¹˜)\n",
        "mask_positions = (input_ids == mask_token_id).nonzero(as_tuple=False)\n",
        "assert mask_positions.numel() > 0, \"ë¬¸ì¥ì— [MASK] í† í°ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "# 9. ëª¨ë¸ ì¶”ë¡ \n",
        "outputs = model(**encoded)\n",
        "\n",
        "# 10. ìœ„ì¹˜ë³„ vocab ë¡œì§“\n",
        "logits = outputs.logits.squeeze(0)  # (seq_len, vocab_size)\n",
        "\n",
        "# 11. ëª¨ë“  [MASK] ìœ„ì¹˜ì— ëŒ€í•´ ì˜ˆì¸¡\n",
        "all_token_candidates: List[List[Tuple[str, float]]] = []\n",
        "for _, pos in mask_positions:\n",
        "    pos = pos.item()\n",
        "    logits_at_pos = logits[pos]                      # (vocab_size,)\n",
        "    probs = torch.softmax(logits_at_pos, dim=-1)     # í™•ë¥ í™”\n",
        "    topk = torch.topk(probs, k=top_k)                # ìƒìœ„ K\n",
        "\n",
        "    ids = topk.indices.tolist()\n",
        "    scores = topk.values.tolist()\n",
        "    tokens = [tokenizer.convert_ids_to_tokens(tid) for tid in ids]\n",
        "\n",
        "    candidates = list(zip(tokens, scores))\n",
        "    all_token_candidates.append(candidates)\n",
        "\n",
        "# 12. ë³µì› ë¬¸ì¥ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
        "restored_sentences: List[str] = []\n",
        "\n",
        "# 13. ì²« ë²ˆì§¸ [MASK] ìœ„ì¹˜ í›„ë³´ë“¤ë§Œ ì‚¬ìš© (ì—¬ëŸ¬ MASKë©´ í•„ìš”ì— ë”°ë¼ í™•ì¥)\n",
        "token_candidates: List[Tuple[str, float]] = all_token_candidates[0]\n",
        "\n",
        "# 14. í›„ë³´ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© [MASK] ìë¦¬ì— ë„£ì–´ ë¬¸ì¥ ë³µì›\n",
        "for tok, _ in token_candidates:\n",
        "    new_ids = input_ids.clone()\n",
        "    tok_id = tokenizer.convert_tokens_to_ids(tok)\n",
        "    new_ids[0, mask_positions[0, 1]] = tok_id\n",
        "    text = tokenizer.decode(new_ids[0], skip_special_tokens=True)\n",
        "    restored_sentences.append(text.strip())\n",
        "\n",
        "# 15. ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ì›ë³¸ ë¬¸ì¥:\", sentence)\n",
        "print(\"BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\")\n",
        "for idx, sent in enumerate(restored_sentences, start=1):\n",
        "    print(f\"{idx}ìˆœìœ„: {sent}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9e04c7",
      "metadata": {
        "id": "be9e04c7"
      },
      "source": [
        "Only Decoder ëª¨ë¸ì˜ ëŒ€í‘œì¸ GPT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "GPT-2 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "6a49ab04",
      "metadata": {
        "id": "6a49ab04"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0feb32c0",
      "metadata": {
        "id": "0feb32c0"
      },
      "source": [
        "GPT-2 ëª¨ë¸ì€ ì…ë ¥ìœ¼ë¡œ í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë°›ê³ , ê·¸ ë’¤ì— ì˜¬ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡(Next token Prediction)í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ ìŠ¤í† ë¦¬(ì…ë ¥ í…ìŠ¤íŠ¸)ì˜ ë’· ë‚´ìš©ì„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "33182f00",
      "metadata": {
        "id": "33182f00",
        "outputId": "19cd5d1b-3d1e-4fff-8686-4656a782ec2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a small village, a curious child found a mysterious key. The child was a boy named Kiyoshi. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Once upon a time in a small village, a curious child found a mysterious key.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "    )\n",
        "\n",
        "output_tokens = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(output_tokens)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "c10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}