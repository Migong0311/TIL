{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Migong0311/TIL/blob/october/practice/3weeks/1017/(%EC%8B%A4%EC%8A%B5_%EB%AC%B8%EC%A0%9C)3_1_Transfer_Learning_%EA%B8%B0%EB%B0%98%EC%9D%98_CNN_%EB%AA%A8%EB%8D%B8_%ED%95%99%EC%8A%B5_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9u2lnjI8fH6"
      },
      "source": [
        "\n",
        "# ğŸ§  [ì‹¤ìŠµ] Transfer Learning ê¸°ë°˜ì˜ CNN ëª¨ë¸ í•™ìŠµ ë° ViT í™œìš© ì´ë¯¸ì§€ ë¶„ë¥˜\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 1ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ (Data Transformation)\n",
        "\n",
        "* ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì‹ ê²½ë§ ì…ë ¥ í¬ê¸°(224Ã—224)ë¡œ ë§ì¶”ê³  ì •ê·œí™”(Normalization) ìˆ˜í–‰\n",
        "* CIFAR-10 í‰ê· (mean), í‘œì¤€í¸ì°¨(std)ë¥¼ ì‚¬ìš©\n",
        "* í•™ìŠµ(train)ê³¼ í…ŒìŠ¤íŠ¸(test)ìš© ë³€í™˜ê¸°ë¥¼ ê°ê° ì •ì˜\n",
        "\n",
        "```python\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> ëª¨ë¸ í•™ìŠµì´ ì•ˆì •ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ë„ë¡ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì •ê·œí™” ë° í†µì¼ëœ í¬ê¸°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 2ï¸âƒ£ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” êµ¬ì„±\n",
        "\n",
        "* CIFAR-10 ë°ì´í„°ì…‹(50,000ì¥ train, 10,000ì¥ test)ì„ ë¡œë“œ\n",
        "* `DataLoader`ë¥¼ ì´ìš©í•´ ë¯¸ë‹ˆë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ëª¨ë¸ì— ê³µê¸‰\n",
        "\n",
        "```python\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
        "testloader  = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê³µê¸‰í•˜ê³ , GPU í•™ìŠµì— ì í•©í•œ í˜•íƒœë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 3ï¸âƒ£ ëª¨ë¸ ìˆ˜ì • (ResNet-18 ê¸°ë°˜ Transfer Learning)\n",
        "\n",
        "* ì‚¬ì „í•™ìŠµëœ **ResNet-18 (ImageNet Pretrained)** ëª¨ë¸ ì‚¬ìš©\n",
        "* ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ(`fc`)ì„ CIFAR-10ì— ë§ê²Œ **10ê°œì˜ í´ë˜ìŠ¤**ë¡œ êµì²´\n",
        "\n",
        "```python\n",
        "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> ê¸°ì¡´ ëª¨ë¸ì˜ íŠ¹ì„± ì¶”ì¶œê¸°(Feature Extractor)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ ,\n",
        "> ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸°ë§Œ êµì²´í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì— ë§ê²Œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 4ï¸âƒ£ íŒŒë¼ë¯¸í„° ë™ê²° (Freeze)\n",
        "\n",
        "* **ì„ í˜• í”„ë¡œë¹™(Linear Probing)**:\n",
        "  ì‚¬ì „ í•™ìŠµëœ íŒŒë¼ë¯¸í„°ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  **ë§ˆì§€ë§‰ ë ˆì´ì–´(fc)** ë§Œ í•™ìŠµí•˜ë„ë¡ ì„¤ì •\n",
        "\n",
        "```python\n",
        "for name, param in model.named_parameters():\n",
        "    if \"fc\" not in name:\n",
        "        param.requires_grad = False\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> ì´ë¯¸ í•™ìŠµëœ íŠ¹ì§•(feature)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ ,\n",
        "> ìƒˆ ë°ì´í„°ì…‹ì— ëŒ€í•œ ë¶„ë¥˜ê¸°ë§Œ í•™ìŠµí•˜ì—¬ ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ì„±ëŠ¥ í–¥ìƒ.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 5ï¸âƒ£ ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
        "\n",
        "* **ì†ì‹¤ í•¨ìˆ˜ (Loss):** CrossEntropyLoss\n",
        "* **ì˜µí‹°ë§ˆì´ì €:** SGD, í•™ìŠµë¥  0.001\n",
        "* **fc ë ˆì´ì–´ë§Œ ì—…ë°ì´íŠ¸ë˜ë„ë¡ ì„¤ì •**\n",
        "\n",
        "```python\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 6ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ë£¨í”„\n",
        "\n",
        "* ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” â†’ ìˆœì „íŒŒ â†’ ì†ì‹¤ ê³„ì‚° â†’ ì—­ì „íŒŒ â†’ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "* ê° epochë§ˆë‹¤ í‰ê·  ì†ì‹¤ ì¶œë ¥\n",
        "\n",
        "```python\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(trainloader)\n",
        "    print(f\"[Epoch {epoch+1}/{num_epochs}] í‰ê·  í›ˆë ¨ ì†ì‹¤: {avg_loss:.4f}\")\n",
        "```\n",
        "\n",
        "> ğŸ§© **í•µì‹¬ ë¡œì§:**\n",
        "> `forward â†’ loss â†’ backward â†’ step()`\n",
        "> ì„ í†µí•´ ëª¨ë¸ì´ CIFAR-10ì˜ ê° í´ë˜ìŠ¤(ë¹„í–‰ê¸°, ìë™ì°¨, ê³ ì–‘ì´ ë“±)ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 7ï¸âƒ£ ëª¨ë¸ í‰ê°€ (Accuracy ê³„ì‚°)\n",
        "\n",
        "* í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
        "* `torch.max()`ë¥¼ ì´ìš©í•´ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë„ì¶œ ë° ì •í™•ë„ ê³„ì‚°\n",
        "\n",
        "```python\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(testloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„: {accuracy:.2f}%\")\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> í•™ìŠµë˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ì—ì„œì˜ **ì¼ë°˜í™” ì„±ëŠ¥** í‰ê°€.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 8ï¸âƒ£ ë°ì´í„° ì¦ê°• (Data Augmentation)\n",
        "\n",
        "* ì´ë¯¸ì§€ì— **RandomCrop + RandomHorizontalFlip** ì¶”ê°€\n",
        "* ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì— ë„ì›€\n",
        "\n",
        "```python\n",
        "train_transform_aug = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 9ï¸âƒ£ ë¯¸ì„¸ ì¡°ì • (Fine-Tuning)\n",
        "\n",
        "* ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ ë™ê²° í•´ì œ (`requires_grad=True`)\n",
        "* ëª¨ë¸ ì „ì²´ë¥¼ í•™ìŠµì‹œì¼œ CIFAR-10ì— ì™„ì „íˆ ì ì‘í•˜ë„ë¡ ì¡°ì •\n",
        "\n",
        "```python\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "```\n",
        "\n",
        "* í•™ìŠµë¥ ì„ ë‚®ê²Œ ì„¤ì •í•œ ì˜µí‹°ë§ˆì´ì €ë¡œ ì „ì²´ ë ˆì´ì–´ ì—…ë°ì´íŠ¸\n",
        "\n",
        "```python\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ ğŸ”Ÿ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš©\n",
        "\n",
        "* í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì ì°¨ ê°ì†Œì‹œì¼œ ì•ˆì •ì ì¸ ìˆ˜ë ´ ìœ ë„\n",
        "\n",
        "```python\n",
        "scheduler.step()\n",
        "```\n",
        "\n",
        "> ğŸ§© ì˜ˆì‹œ:\n",
        ">\n",
        "> ```python\n",
        "> scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "> ```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 11ï¸âƒ£ Vision Transformer (ViT) ëª¨ë¸ ë¡œë“œ\n",
        "\n",
        "* HuggingFace Hubì—ì„œ **ì‚¬ì „í•™ìŠµëœ ViT ëª¨ë¸**ê³¼ **ì „ì²˜ë¦¬ê¸°** ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "```python\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "\n",
        "model_name = \"nateraw/vit-base-patch16-224-cifar10\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "vit_model = ViTForImageClassification.from_pretrained(model_name)\n",
        "vit_model.to(device)\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> Transformer ê¸°ë°˜ êµ¬ì¡°(ViT)ë¥¼ ì‚¬ìš©í•˜ì—¬ CNNë³´ë‹¤ ë” íš¨ìœ¨ì ì¸ ì‹œê°ì  íŒ¨í„´ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ 12ï¸âƒ£ Hugging Face íŒŒì´í”„ë¼ì¸ì„ ì´ìš©í•œ ì˜ˆì¸¡\n",
        "\n",
        "* `pipeline(\"image-classification\")`ì„ í†µí•´ ì†ì‰½ê²Œ ì´ë¯¸ì§€ ë¶„ë¥˜ ìˆ˜í–‰\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "clf = pipeline(\"image-classification\", model=model_name, device=device)\n",
        "preds = clf(\"cat_image.jpg\")\n",
        "print(preds)\n",
        "```\n",
        "\n",
        "ğŸ“ˆ **ì¶œë ¥ ì˜ˆì‹œ**\n",
        "\n",
        "```python\n",
        "[{'label': 'cat', 'score': 0.9982},\n",
        " {'label': 'dog', 'score': 0.0011}]\n",
        "```\n",
        "\n",
        "> ğŸ§© **ëª©ì :**\n",
        "> ë³µì¡í•œ ì „ì²˜ë¦¬ ê³¼ì •ì„ ìë™í™”í•˜ê³ ,\n",
        "> ë‹¨ í•œ ì¤„ì˜ ì½”ë“œë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ¯ **ìµœì¢… ìš”ì•½**\n",
        "\n",
        "| ë‹¨ê³„    | í•µì‹¬ ê°œë…                   | ì£¼ìš” ëª©ì                        |\n",
        "| ----- | ----------------------- | --------------------------- |\n",
        "| 1~2   | ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë”©            | ì´ë¯¸ì§€ ì •ê·œí™” ë° DataLoader êµ¬ì„±     |\n",
        "| 3~5   | ëª¨ë¸ ìˆ˜ì • ë° ë™ê²°              | ResNet18ì„ CIFAR-10ìš©ìœ¼ë¡œ ë³€í™˜    |\n",
        "| 6~7   | í•™ìŠµ ë° í‰ê°€                 | CrossEntropyLoss, SGD ê¸°ë°˜ í›ˆë ¨ |\n",
        "| 8     | ë°ì´í„° ì¦ê°•                  | ì¼ë°˜í™” í–¥ìƒ                      |\n",
        "| 9~10  | Fine-Tuning + Scheduler | ëª¨ë¸ ì „ì²´ ì¬í•™ìŠµ + ì•ˆì •ì  ìˆ˜ë ´          |\n",
        "| 11~12 | Vision Transformer ì ìš©   | ì‚¬ì „í•™ìŠµëœ ViT ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜        |\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **ê²°ë¡ :**\n",
        "ì´ë²ˆ ì‹¤ìŠµì€\n",
        "\n",
        "> â€œì‚¬ì „í•™ìŠµëœ ëª¨ë¸(ResNet18, ViT)ì„ í™œìš©í•˜ì—¬ CIFAR-10 ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ê³ ,\n",
        "> ì„ í˜• í”„ë¡œë¹™ â†’ ë¯¸ì„¸ì¡°ì •(Fine-Tuning) â†’ Transformer í™•ì¥ê¹Œì§€â€\n",
        "> ì „ ê³¼ì •ì„ ê²½í—˜í•˜ëŠ” **Transfer Learningì˜ í•µì‹¬ ì‹¤ìŠµ**ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af5r70FJ9Fbr"
      },
      "source": [
        "# **Objectives**\n",
        "\n",
        "1. ì‹¤ìŠµ ê°œìš”\n",
        "  - ì‚¬ì „ í•™ìŠµëœ CNN ëª¨ë¸(ResNet-18)ì„ í™œìš©í•œ ë¦¬ë‹ˆì–´ í”„ë¡œë¹™ (Linear Probing)\n",
        "  - ë°ì´í„° ì¦ê°• (Augmentation) ë° ë¯¸ì„¸ ì¡°ì • (Fine-tuning) ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ\n",
        "  - HuggingFace ViT ëª¨ë¸ì„ í†µí•œ ìµœì‹  íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì¶”ë¡  ì²´í—˜\n",
        "\n",
        "2. ì‹¤ìŠµ ì§„í–‰ ëª©ì  ë° ë°°ê²½\n",
        "  - ì „ì´ í•™ìŠµ(Transfer Learning)ì˜ ê°œë…ê³¼ íš¨ê³¼ì ì¸ ì ìš© ë°©ë²• ì´í•´\n",
        "  - ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•œ íš¨ìœ¨ì ì¸ í•™ìŠµ ë°©ì‹ ì²´í—˜\n",
        "  - CNN ê¸°ë°˜ ëª¨ë¸ê³¼ Transformer ê¸°ë°˜ ëª¨ë¸ì˜ ì°¨ì´ ë° í™œìš©ë²• ë¹„êµ\n",
        "  - PyTorch ë° HuggingFace ìƒíƒœê³„ë¥¼ í™œìš©í•œ ì‹¤ì „ ë¹„ì „ ëª¨ë¸ êµ¬ì¶•\n",
        "\n",
        "3. ì‹¤ìŠµ ìˆ˜í–‰ìœ¼ë¡œ ì–»ì–´ê°ˆ ìˆ˜ ìˆëŠ” ì—­ëŸ‰\n",
        "  - ResNet-18ê³¼ ê°™ì€ CNN ëª¨ë¸ êµ¬ì¡° ë° ì „ì´ í•™ìŠµ í™œìš©ë²• ìˆ™ì§€\n",
        "  - ëª¨ë¸ì˜ ì¼ë¶€ ê³„ì¸µë§Œ í•™ìŠµì‹œí‚¤ëŠ” Linear Probing ì „ëµ ì´í•´\n",
        "  - Data Augmentation, Learning Rate Scheduler ë“± ì„±ëŠ¥ ê°œì„  ê¸°ë²• ì ìš© ëŠ¥ë ¥\n",
        "  - HuggingFace ëª¨ë¸ ë¡œë”© ë° Inference Pipeline í™œìš©ë²• ì‹¤ìŠµ\n",
        "\n",
        "4. ì‹¤ìŠµ í•µì‹¬ ë‚´ìš©\n",
        "  - ì‚¬ì „ í•™ìŠµëœ ResNet-18 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ í•™ìŠµ (Linear Probing)\n",
        "  - ì „ì²´ ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ Fine-tuning ìˆ˜í–‰ (with Augmentation & Scheduler)\n",
        "  - HuggingFaceì˜ Vision Transformer(ViT) ëª¨ë¸ë¡œ CIFAR-10 ì´ë¯¸ì§€ ì¶”ë¡ \n",
        "  - í•™ìŠµ ê²°ê³¼ì˜ ì •í™•ë„ ë¹„êµ ë° ì „ì´ í•™ìŠµì˜ íš¨ê³¼ ì²´í—˜\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xhVPV2X2O_"
      },
      "source": [
        "# **Prerequisites**\n",
        "```bash\n",
        "torch:  2.6.0+cu124\n",
        "torchvision:  0.21.0+cu124\n",
        "transformers:  4.55.1\n",
        "datasets:  4.0.0\n",
        "\n",
        "# !pip install torch torchvision numpy datasets transformers\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zqZoW7JrMOk"
      },
      "source": [
        "\n",
        "# **Exercise Overview**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ì´ Jupyter ë…¸íŠ¸ë¶ì—ì„œëŠ” CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì»´í“¨í„° ë¹„ì „ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ë°°ì›Œë´…ë‹ˆë‹¤. íŠ¹íˆ ì „ì´ í•™ìŠµ (Transfer Learning) ì„ í†µí•´ ë¹ ë¥´ê²Œ ëª¨ë¸ì„ ìƒˆë¡œìš´ ë°ì´í„°ì— ì ì‘ì‹œí‚¤ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
        "\n",
        "### **ë“¤ì–´ê°€ë©°: ì „ì´í•™ìŠµ (Transfer Learning) ì´ë€?**\n",
        "ì „ì´í•™ìŠµ(Transfer Learning)ì€ ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìƒˆë¡œìš´ ë¬¸ì œì— í™œìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” CNNì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:\n",
        "\n",
        "```\n",
        "[ì…ë ¥ ì´ë¯¸ì§€] â†’ [íŠ¹ì§• ì¶”ì¶œ (Convolution + Pooling)] â†’ [ë¶„ë¥˜ (FullyConnected Layers)] â†’ [ì¶œë ¥]\n",
        "```\n",
        "\n",
        "- CNNì—ì„œ í•©ì„±ê³± (Convolution)ê³¼ í’€ë§ (Pooling)ì€ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ, ì´ë¯¸ì§€ë‚˜ ë°ì´í„°ì˜ íŠ¹ì§•(feature)ì„ ì ì  ë” ì¶”ìƒí™”í•˜ë©° ì¶”ì¶œí•´ ë‚˜ê°€ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
        "- ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ Fully Connected Layer (Dense Layer) ëŠ” íŠ¹ì§• ì¶”ì¶œ ì´í›„ì˜ ìµœì¢…ì ì¸ ê²°ë¡ ì„ ë‚´ë¦¬ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ì´ë•Œì— CNN ì´ í•™ìŠµí•˜ëŠ” íŠ¹ì§•ë“¤ì€ ë§¤ìš° ì¼ë°˜ì ì¸ íŠ¹ì§• (ì—£ì§€, ìƒ‰ìƒ, ì„ , ì§ˆê°, ë‹¨ìˆœí•œ íŒ¨í„´ì´ë‚˜ ëª¨ì–‘) ë“±ì„ í¬í•¨í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë‹¤ì–‘í•œ ì´ë¯¸ì§€ì—ì„œ ê³µí†µìœ¼ë¡œ ìœ ìš©í•©ë‹ˆë‹¤. ë•Œë¬¸ì— ë‹¤ë¥¸ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ, í•´ë‹¹ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ë”ìš± ë¹ ë¥´ê²Œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "\n",
        "ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ê²½ìš°ëŠ” íƒœìŠ¤í¬ì— íŠ¹í™”ëœ ì •ë³´ë¥¼ ë‹´ê³  ìˆì–´ì„œ ì¬í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "### **ì‹¤ìŠµ ëª©ì°¨**\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ì„¸ ê°€ì§€ ì£¼ìš” íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. ResNet-18 ì„ í˜• í”„ë¡œë¹™(Linear Probing): ì‚¬ì „ í•™ìŠµëœ ResNet-18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ íŠ¹ì„± ì¶”ì¶œ ë¶€ë¶„ì„ ë™ê²°í•˜ê³  ë§ˆì§€ë§‰ ë¶„ë¥˜ ì¸µë§Œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
        "2. ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•: ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ ì¶”ê°€í•˜ê³ , ëª¨ë¸ì˜ ëª¨ë“  ì¸µì„ ë¯¸ì„¸ ì¡°ì •(fine-tuning)í•˜ë©°, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë„ì…í•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "3. HuggingFaceë¥¼ ì‚¬ìš©í•œ Vision Transformer(ViT) ì¶”ë¡ : HuggingFace ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì‚¬ì „ í•™ìŠµëœ ViT ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ CIFAR-10 ì´ë¯¸ì§€ì— ëŒ€í•œ ë¶„ë¥˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ , ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0tHgw9t5AkU"
      },
      "source": [
        "ë¨¼ì € ì‹¤ìŠµ ì „ì— ì¬í˜„ì„±ì„ ìœ„í•˜ì—¬ PyTorch, NumPy, ê·¸ë¦¬ê³  Python ì˜ random ëª¨ë“ˆì— ëŒ€í•œ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h7oD_ZKu41lQ"
      },
      "outputs": [],
      "source": [
        "# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "# --- ì‹œë“œ ê³ ì • ---\n",
        "# PyTorchì˜ CPU ì—°ì‚° ì‹œë“œ ê³ ì •\n",
        "torch.manual_seed(42)\n",
        "# PyTorchì˜ GPU ì—°ì‚° ì‹œë“œ ê³ ì •\n",
        "torch.cuda.manual_seed(42)\n",
        "# NumPyì˜ ë‚œìˆ˜ ì‹œë“œ ê³ ì •\n",
        "np.random.seed(42)\n",
        "# Python ë‚´ì¥ random ëª¨ë“ˆì˜ ì‹œë“œ ê³ ì •\n",
        "random.seed(42)\n",
        "\n",
        "# CuDNN ê´€ë ¨ ì„¤ì • (GPU ì—°ì‚°ì˜ ì¬í˜„ì„±ì„ ìœ„í•¨)\n",
        "# ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•˜ì—¬ ì‹¤í–‰ ì‹œë§ˆë‹¤ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¥\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# ë‚´ì¥ëœ ë²¤ì¹˜ë§ˆí¬ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì¬í˜„ì„± ìœ ì§€\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piQVxOharpTN"
      },
      "source": [
        "## **1. ResNet-18ì„ ì´ìš©í•œ ì„ í˜• í”„ë¡œë¹™ (Linear Probing)**\n",
        "\n",
        "Linear Probingì€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ëŒ€ë¶€ë¶„ì„ ë™ê²°(freeze) ì‹œí‚¤ê³  ë§ˆì§€ë§‰ ê³„ì¸µ(ë¶„ë¥˜ê¸°)ë§Œ í•™ìŠµí•˜ëŠ” ì „ì´ í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤. ImageNet ê°™ì´ ê±°ëŒ€í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ í’ë¶€í•œ íŠ¹ì„± í‘œí˜„ì„ í™œìš©í•˜ê³ , CIFAR-10ì— ë§ë„ë¡ ì¶œë ¥ ê³„ì¸µë§Œ ìƒˆë¡œ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë³µì¡í•œ ëª¨ë¸ì˜ ë§ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì¬í•™ìŠµí•  í•„ìš” ì—†ì´ë„ ìƒˆë¡œìš´ ì‘ì—…ì— ì ì‘í•  ìˆ˜ ìˆìœ¼ë©°, í›ˆë ¨ ì‹œê°„ë„ ë‹¨ì¶•ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ì„¹ì…˜ì—ì„œëŠ” PyTorchì˜ `torchvision.models`ì—ì„œ ResNet-18 ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¨ ë’¤, ë§ˆì§€ë§‰ ì¶œë ¥ ì¸µì„ CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ì— ë§ê²Œ êµì²´í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë§ˆì§€ë§‰ ì¸µì„ ì œì™¸í•œ ëª¨ë“  ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ ë™ê²°í•˜ì—¬ í•´ë‹¹ ì¸µë“¤ì€ í•™ìŠµ ë™ì•ˆ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤. PyTorchì—ì„œëŠ” `requires_grad = False` ì„¤ì •ì„ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ë™ê²°í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë ‡ê²Œ í•˜ë©´ ì—­ì „íŒŒ ì‹œì— í•´ë‹¹ íŒŒë¼ë¯¸í„°ë“¤ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê³„ì‚°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S3rbZ9FsL2z"
      },
      "source": [
        "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjcGgq0QldJL",
        "outputId": "f8c6206f-4183-4c0c-89af-ee2bc8437d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: cuda\n"
          ]
        }
      ],
      "source": [
        "# --- í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---\n",
        "import torch\n",
        "import torch.nn as nn                       # ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ (ë ˆì´ì–´, ì†ì‹¤ í•¨ìˆ˜ ë“±)\n",
        "import torch.optim as optim                 # ëª¨ë¸ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ (SGD, Adam ë“±)\n",
        "import torchvision                          # ì»´í“¨í„° ë¹„ì „ ê´€ë ¨ ìœ ëª… ë°ì´í„°ì…‹, ëª¨ë¸, ë³€í™˜ ê¸°ëŠ¥ì„ ì œê³µ\n",
        "import torchvision.transforms as transforms # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬(ë³€í™˜)í•˜ê¸° ìœ„í•œ ê¸°ëŠ¥\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- ì¥ì¹˜ ì„¤ì • ---\n",
        "# torch.cuda.is_available() í•¨ìˆ˜ëŠ” GPU ì‚¬ìš©ì´ ê°€ëŠ¥í•œì§€ í™•ì¸\n",
        "# ê°€ëŠ¥í•˜ë©´ 'cuda' (GPU)ë¥¼, ë¶ˆê°€ëŠ¥í•˜ë©´ 'cpu'ë¥¼ device ë³€ìˆ˜ì— í• ë‹¹\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n80N9S4mtyRH"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
        "\n",
        "TorchVisionì„ ì´ìš©í•´ CIFAR-10 ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , í•„ìš”í•œ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "1. CIFAR-10 ë°ì´í„°ë¥¼ ResNet-18 ì˜ ì…ë ¥ì— ë§ê²Œ 224x224 ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "2. ë°ì´í„°ì—ëŠ” ì •ê·œí™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "ì •ê·œí™”ì—ëŠ” CIFAR-10 ë°ì´í„°ì…‹ì˜ í”½ì…€ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê°’ì„ ì‚¬ìš©í•˜ë©°, ì´ëŠ” ëª¨ë¸ì´ ì…ë ¥ì„ ë³´ë‹¤ ì•ˆì •ì ìœ¼ë¡œ ë°›ì•„ë“¤ì´ê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCOJMDIuZ4S",
        "outputId": "8421ea09-7a8f-4d66-8273-6c6ae72caa7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:05<00:00, 29.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ (train 50,000ì¥, test 10,000ì¥)\n",
        "# --- CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ ---\n",
        "# root: ë°ì´í„°ê°€ ì €ì¥ë  ê²½ë¡œ\n",
        "# train=True: í›ˆë ¨ìš© ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜´\n",
        "# download=True: í•´ë‹¹ ê²½ë¡œì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ\n",
        "# transform: ë°ì´í„° ë³€í™˜ê¸° ì ìš© -> ë°ì´í„°ë¥¼ ë¨¼ì € í™•ì¸í•˜ê¸° ìœ„í•´ False ìœ¼ë¡œ ì„¤ì •\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=False)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=False)\n",
        "\n",
        "print(trainset.data.shape, testset.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMDfZJwiurUe",
        "outputId": "4b2554e7-9a29-44ca-b5ce-0c051207175f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 í•™ìŠµ ë°ì´í„°ì˜ í”½ì…€ë³„ í‰ê· : tensor([0.4914, 0.4822, 0.4465])\n",
            "CIFAR-10 í•™ìŠµ ë°ì´í„°ì˜ í”½ì…€ë³„ í‘œì¤€í¸ì°¨: tensor([0.2470, 0.2435, 0.2616])\n"
          ]
        }
      ],
      "source": [
        "# CIFAR_10 ë°ì´í„°ì…‹ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
        "data_tensor = torch.from_numpy(trainset.data)\n",
        "\n",
        "# í‰ê·  ê³„ì‚° (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„ ì°¨ì›ì— ëŒ€í•´)\n",
        "mean = torch.mean(data_tensor.float() / 255.0, dim=(0, 1, 2))\n",
        "\n",
        "# í‘œì¤€í¸ì°¨ ê³„ì‚° (ë°°ì¹˜, ë†’ì´, ë„ˆë¹„ ì°¨ì›ì— ëŒ€í•´)\n",
        "std = torch.std(data_tensor.float() / 255.0, dim=(0, 1, 2))\n",
        "\n",
        "print(\"CIFAR-10 í•™ìŠµ ë°ì´í„°ì˜ í”½ì…€ë³„ í‰ê· :\", mean)\n",
        "print(\"CIFAR-10 í•™ìŠµ ë°ì´í„°ì˜ í”½ì…€ë³„ í‘œì¤€í¸ì°¨:\", std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK_9HrJXuFa4",
        "outputId": "869c333b-5f79-4eba-c244-b0241438c3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í›ˆë ¨ ë°°ì¹˜ ê°œìˆ˜: 196 í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ê°œìˆ˜: 40\n"
          ]
        }
      ],
      "source": [
        "# --- ë°ì´í„° ë³€í™˜ê¸°(Transformer) ì •ì˜ ---\n",
        "# ì´ë¯¸ì§€ì— ì ìš©í•  ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ Composeë¥¼ ì‚¬ìš©í•´ ë¬¶ì–´ì¤ë‹ˆë‹¤.\n",
        "\n",
        "# í•™ìŠµ ë°ì´í„° ë³€í™˜ê¸°\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),      # ResNet18 ì…ë ¥ í¬ê¸°ì¸ 224x224ë¡œ í¬ê¸° ë³€ê²½\n",
        "    transforms.ToTensor(),              # PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "    transforms.Normalize(mean, std)     # í”½ì…€ ê°’ ì •ê·œí™”\n",
        "])\n",
        "\n",
        "# ë¬¸ì œ 1: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ê¸° ì •ì˜\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°: ë¦¬ì‚¬ì´ì¦ˆ í›„ í…ì„œí™” ë° ì •ê·œí™” (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ)\n",
        "test_transform = transforms.Compose([\n",
        "    # [START CODE]\n",
        "    transforms.Resize((224, 224)),      # ì…ë ¥ í¬ê¸° í†µì¼\n",
        "    transforms.ToTensor(),              # í…ì„œ ë³€í™˜\n",
        "    transforms.Normalize(mean, std)     # ì •ê·œí™”\n",
        "    # [END CODE]\n",
        "])\n",
        "\n",
        "# --- CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ ---\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# --- DataLoader ìƒì„± ---\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
        "testloader  = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(\"í›ˆë ¨ ë°°ì¹˜ ê°œìˆ˜:\", len(trainloader), \"í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ê°œìˆ˜:\", len(testloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWvr986KsSbm"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ TorchVision ìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ ResNet-18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  , CIFAR-10ì— ë§ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤. ê¸°ë³¸ ResNet-18 ëª¨ë¸ì€ ImageNetì˜ 1000ê°œ í´ë˜ìŠ¤ë¡œ í›ˆë ¨ë˜ì—ˆìœ¼ë¯€ë¡œ ë§ˆì§€ë§‰ ì¶œë ¥ ë‰´ëŸ° ìˆ˜ê°€ 1000ì…ë‹ˆë‹¤. ì´\n",
        "ë¥¼ CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ìµœì¢… Fully Connected Layer ì„ ìƒˆë¡œìš´ ë ˆì´ì–´ë¡œ êµì²´í•©ë‹ˆë‹¤.\n",
        "\n",
        "ìƒˆë¡œ ì¶”ê°€ëœ Fully Connected Layer ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ëŠ” ë™ê²°ì‹œì¼œ, ì—…ë°ì´íŠ¸ê°€ ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz_tu9RlrEZ6",
        "outputId": "93bd0125-cc4d-46ad-ae2b-db8ac2a47adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 85.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# ImageNet ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ResNet-18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´\n",
        "# pretrained=True ì˜µì…˜ì€ í•™ìŠµëœ ê°€ì¤‘ì¹˜(weights)ë¥¼ í•¨ê»˜ ê°€ì ¸ì˜¤ë¼ëŠ” ì˜ë¯¸\n",
        "model = torchvision.models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rSoBnKGs1Jt",
        "outputId": "823fac65-afe9-4fc4-b5a1-5cfbc9de7a05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥. ë§ˆì§€ë§‰ ë ˆì´ì–´ (Fully Connected Layer) ì˜ ì´ë¦„ì´ fc ì¸ ê²ƒì„ í™•ì¸\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pOOf1AWys0SJ"
      },
      "outputs": [],
      "source": [
        "# --- ì„ í˜• í”„ë¡œë¹™(Linear Probing)ì„ ìœ„í•œ ëª¨ë¸ ìˆ˜ì • ---\n",
        "\n",
        "# ë¬¸ì œ 2: ì„ í˜• í”„ë¡œë¹™ì„ ìœ„í•´ ResNet-18 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì¸µì„ ìˆ˜ì •í•˜ì„¸ìš”.\n",
        "# 1. ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ(Fully Connected Layer) êµì²´\n",
        "# ê¸°ì¡´ ResNet-18ì˜ ë§ˆì§€ë§‰ ì¸µ(model.fc)ì€ ImageNetì˜ 1000ê°œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜\n",
        "# ì´ë¥¼ CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ë„ë¡ ìƒˆë¡œìš´ ì„ í˜• ë ˆì´ì–´ë¡œ êµì²´\n",
        "# model.fc.in_featuresëŠ” ê¸°ì¡´ fc ë ˆì´ì–´ì˜ ì…ë ¥ ë‰´ëŸ° ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "# [START CODE]\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, 10)   # CIFAR-10: 10 í´ë˜ìŠ¤\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# ë¬¸ì œ 3: ì„ í˜• í”„ë¡œë¹™ì„ ìœ„í•´ ResNet-18 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì¸µì„ ì—…ë°ì´íŠ¸ê°€ ë˜ì§€ ì•Šë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë™ê²°í•˜ì„¸ìš”.\n",
        "# 2. ë§ˆì§€ë§‰ ì¸µì„ ì œì™¸í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜)ë¥¼ ë™ê²°(freeze)\n",
        "# == ìµœì¢… fc ë ˆì´ì–´ë¥¼ ì œì™¸í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë™ê²°\n",
        "# `param.requires_grad = False`ë¡œ ì„¤ì •í•˜ë©´ í•´ë‹¹ íŒŒë¼ë¯¸í„°ëŠ” í•™ìŠµ ì¤‘ì— ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ\n",
        "# [START CODE]\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "# fcë§Œ í•™ìŠµë˜ë„ë¡ í’€ì–´ì£¼ê¸°\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# ì¥ì¹˜ë¥¼ GPUë¡œ ì´ë™\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKVaxojstOca"
      },
      "source": [
        "ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ (ë¶„ë¥˜ì¸µ) ë§Œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, í•™ìŠµë¥ , ì—í¬í¬ ìˆ˜ ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "1. ì†ì‹¤ í•¨ìˆ˜ (criterion) ë¡œëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨(nn.CrossEntropyLoss)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "2. ì˜µí‹°ë§ˆì´ì € (optimizer) ë¡œëŠ” ë¶„ë¥˜ì¸µ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸í•˜ë„ë¡ SGD(Stochastic Gradient Descent)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "3. í•™ìŠµë¥ (lr)ì€ ì˜ˆì‹œë¡œ 0.001ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "4. ì—í¬í¬ ìˆ˜ (epochs) ëŠ” 5ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itQO13ActDO8",
        "outputId": "bfbda1e0-40c7-4d1a-8447-ab1e541e2836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–ˆ        | 1/5 [02:20<09:23, 140.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/5] í‰ê·  í›ˆë ¨ ì†ì‹¤: 1.4357\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì œ 4: ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì„¸ìš”\n",
        "# ì†ì‹¤ í•¨ìˆ˜ë¡œ CrossEntropyLossë¥¼ ì •ì˜\n",
        "# [START CODE]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# ë¬¸ì œ 5: ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•˜ì„¸ìš”\n",
        "# ì˜µí‹°ë§ˆì´ì €ë¡œ SGD(Stochastic Gradient Descent)ë¥¼ ì •ì˜, í•™ìŠµë¥ ì€ 0.001 ìœ¼ë¡œ ì„¤ì •\n",
        "# ë™ê²°ëœ íŒŒë¼ë¯¸í„° ì œì™¸, ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ ìµœì í™”\n",
        "# ì¦‰, ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ íŒŒë¼ë¯¸í„°ë§Œ ì˜µí‹°ë§ˆì´ì €ì— ì „ë‹¬í•˜ì—¬ ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ ìµœì í™”ë˜ë„ë¡ ì„¤ì •\n",
        "# [START CODE]\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# ì—í¬í¬(epoch) ìˆ˜ ì„¤ì •. ì—í¬í¬ëŠ” ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¥¼ í•œ ë²ˆ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì˜ë¯¸\n",
        "num_epochs = 5\n",
        "\n",
        "# ë¬¸ì œ 6: ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°˜ë³µë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()       # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    running_loss = 0.0  # ì—í¬í¬ ë™ì•ˆì˜ ì´ ì†ì‹¤ì„ ê¸°ë¡í•  ë³€ìˆ˜\n",
        "\n",
        "    # trainloaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë°˜ë³µ\n",
        "    for inputs, labels in trainloader:\n",
        "\n",
        "        # ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ ë ˆì´ë¸”ì„ ì§€ì •ëœ ì¥ì¹˜(GPU)ë¡œ ì´ë™\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # --- í•µì‹¬ í•™ìŠµ ë‹¨ê³„ ---\n",
        "        # [START CODE]\n",
        "\n",
        "        # 1. ì˜µí‹°ë§ˆì´ì €ì˜ ê·¸ë˜ë””ì–¸íŠ¸(gradient)ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”\n",
        "        # ì´ì „ ë°°ì¹˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ë‹¤ìŒ ë°°ì¹˜ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•¨\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. ëª¨ë¸ì— ì…ë ¥ì„ ë„£ì–´ ìˆœì „íŒŒ(forward pass) ì§„í–‰ ë° ì¶œë ¥(outputs) ê³„ì‚°\n",
        "        outputs =  model(inputs)\n",
        "\n",
        "        # 3. ëª¨ë¸ì˜ ì¶œë ¥ê³¼ ì‹¤ì œ ì •ë‹µì„ ë¹„êµí•˜ì—¬ ì†ì‹¤(loss) ê³„ì‚°\n",
        "        loss =  criterion(outputs, labels)\n",
        "\n",
        "        # 4. ì—­ì „íŒŒ(backward pass)ë¥¼ í†µí•´ ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜)ë¥¼ ì—…ë°ì´íŠ¸\n",
        "        # requires_grad=Trueë¡œ ì„¤ì •ëœ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸ë¨ (ì—¬ê¸°ì„œëŠ” fc ì¸µë§Œ)\n",
        "        optimizer.step()\n",
        "\n",
        "        # [END CODE]\n",
        "\n",
        "        # í˜„ì¬ ë°°ì¹˜ì˜ ì†ì‹¤ì„ running_lossì— ë”í•¨\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ì „ì²´ ì—í¬í¬ê°€ ëë‚œ í›„ í‰ê·  í›ˆë ¨ ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  ì¶œë ¥\n",
        "    avg_loss = running_loss / len(trainloader)\n",
        "    print(f\"[Epoch {epoch+1}/{num_epochs}] í‰ê·  í›ˆë ¨ ì†ì‹¤: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auk7_cQiwXK_"
      },
      "source": [
        "í›ˆë ¨ì´ ì™„ë£Œëœ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œ(eval)ë¡œ ì „í™˜í•œ ë’¤, CIFAR-10 í…ŒìŠ¤íŠ¸ ë°ì´í„° 10,000ì¥ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ì¸¡ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "í•™ìŠµ ì‹œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì…ë ¥ì„ device(GPU)ì— ì˜¬ë¦¬ê³ , torch.no_grad() ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì¶œë ¥ì„ ì˜ˆì¸¡í•˜ì—¬ ì„±ëŠ¥ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "ImageNet ì— ì‚¬ì „í•™ìŠµëœ ResNet-18 ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì—, ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ í•™ìŠµí•˜ë”ë¼ë„ CIFAR-10 ë°ì´í„°ì— ë¹ ë¥´ê²Œ ì ì‘í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9wcPEIyw0CG"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "# ì´ ëª¨ë“œì—ì„œëŠ” ë“œë¡­ì•„ì›ƒ(Dropout)ì´ë‚˜ ë°°ì¹˜ ì •ê·œí™”(Batch Normalization) ë“±ì´ ë¹„í™œì„±í™”ë˜ì–´ ì¼ê´€ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ\n",
        "model.eval()\n",
        "\n",
        "correct = 0   # ë§ì¶˜ ì˜ˆì¸¡ ê°œìˆ˜\n",
        "total = 0     # ì „ì²´ ë°ì´í„° ê°œìˆ˜\n",
        "\n",
        "# ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸\n",
        "with torch.no_grad():\n",
        "\n",
        "    # testloaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë°˜ë³µ\n",
        "    for inputs, labels in tqdm(testloader):\n",
        "\n",
        "        # ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ ë ˆì´ë¸”ì„ ì¥ì¹˜(GPU)ë¡œ ì´ë™\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # ëª¨ë¸ì— ì…ë ¥ì„ ë„£ì–´ ì¶œë ¥ ê³„ì‚°\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # ë¬¸ì œ 7: ì˜ˆì¸¡ ë° ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì„¸ìš”\n",
        "        # [START CODE]\n",
        "        # --- ì˜ˆì¸¡ ë° ì •í™•ë„ ê³„ì‚° ---\n",
        "        # outputs.dataëŠ” ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥(logits)\n",
        "        # torch.max(..., 1)ì€ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¥ ë†’ì€ ê°’ê³¼ ê·¸ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
        "        # `_`ëŠ” ê°’(ë¬´ì‹œ), `predicted`ëŠ” ì¸ë±ìŠ¤(ì˜ˆì¸¡ëœ í´ë˜ìŠ¤)\n",
        "        _, predicted =  torch.max(outputs.data, 1)\n",
        "        # [END CODE]\n",
        "\n",
        "        total += labels.size(0) # í˜„ì¬ ë°°ì¹˜ì˜ ë°ì´í„° ê°œìˆ˜ë¥¼ totalì— ë”í•¨\n",
        "\n",
        "        # ì˜ˆì¸¡ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ” ê°œìˆ˜ë¥¼ ì„¸ì–´ correctì— ë”í•¨\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# ì „ì²´ ì •í™•ë„ ê³„ì‚° ë° ì¶œë ¥\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKf2m9BsxIUC"
      },
      "source": [
        "# **2. ë°ì´í„° ì¦ê°• (Augmentation) ë° ë¯¸ì„¸ ì¡°ì • (Fine-Tuning), í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (Learning Rate Scheduler) ë¡œ ì„±ëŠ¥ í–¥ìƒ**\n",
        "\n",
        "ë‘ ë²ˆì§¸ ì„¹ì…˜ì—ì„œëŠ” ì²« ë²ˆì§¸ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê¸°ë²•ë“¤ì„ ì ìš©í•©ë‹ˆë‹¤. ì£¼ìš” ì „ëµì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "1. ë°ì´í„° ì¦ê°•(Data Augmentation): í•™ìŠµ ë°ì´í„°ì— ë¬´ì‘ìœ„ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ë°ì´í„° ë‹¤ì–‘ì„±ì„ ë†’ì´ê³  ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤ (ì˜ˆ: ëœë¤ ìë¥´ê¸°, ì¢Œìš° ë’¤ì§‘ê¸° ë“±)\n",
        "\n",
        "2. ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •(Fine-Tuning): ë™ê²°í–ˆë˜ í•©ì„±ê³± ê¸°ë°˜ ì¸µë“¤ì„ ëª¨ë‘ í’€ê³ (unfreeze) ì „ì²´ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ CIFAR-10 ë°ì´í„°ì— ë”ìš± ì˜ ë§ë„ë¡ ìµœì í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "3. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬(Learning Rate Scheduler): í•™ìŠµ ì§„í–‰ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì¡°ì •í•˜ì—¬ ë” ë‚˜ì€ ìˆ˜ë ´ì„ ìœ ë„í•©ë‹ˆë‹¤ (ì˜ˆ: ì¼ì • epochë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ ë˜ëŠ” ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ ë“±)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4s8Yh8o3tUz"
      },
      "source": [
        "ìš°ì„  CIFAR-10 í•™ìŠµ ë°ì´í„°ì— ë¬´ì‘ìœ„ ì¢Œìš° ë’¤ì§‘ê¸°ì™€ ë¬´ì‘ìœ„ ìë¥´ê¸° ì¦ê°•ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. ì´ëŠ” ì…ë ¥ ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ í˜•íƒœì˜ ì™œê³¡ì„ ì£¼ì–´ ëª¨ë¸ì´ ë‹¤ì–‘í•œ íŒ¨í„´ì— ëŒ€í•´ ì¼ë°˜í™”í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤\n",
        "ì´ ê¸°ë²•ì€ ê³¼ì í•©(overfitting)ì„ ì¤„ì´ê³  ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN1AIqVa3rq_"
      },
      "outputs": [],
      "source": [
        "# ë¬¸ì œ 8: ë°ì´í„° ì¦ê°•ì„ ì ìš©í•œ ë³€í™˜ê¸°ë¥¼ ì •ì˜í•˜ì„¸ìš”\n",
        "# --- ë°ì´í„° ì¦ê°•ì´ í¬í•¨ëœ ë³€í™˜ê¸° ì •ì˜ ---\n",
        "train_transform_aug = transforms.Compose([\n",
        "    # [START CODE]\n",
        "    # 32x32 ì´ë¯¸ì§€ ì£¼ë³€ì— 4í”½ì…€ì˜ íŒ¨ë”©(padding)ì„ ì¶”ê°€í•œ ë’¤, ë¬´ì‘ìœ„ë¡œ 32x32 ì˜ì—­ì„ ì˜ë¼ëƒ„\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    # 50% í™•ë¥ ë¡œ ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë’¤ì§‘ìŒ\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # [END CODE]\n",
        "    transforms.Resize((224, 224)), # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì ˆ\n",
        "    transforms.ToTensor(), # í…ì„œë¡œ ë³€í™˜\n",
        "    transforms.Normalize(mean=mean, std=std) # ì •ê·œí™”\n",
        "])\n",
        "\n",
        "# ë°ì´í„° ì¦ê°•ì´ ì ìš©ëœ ìƒˆë¡œìš´ í›ˆë ¨ ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±\n",
        "trainset_aug = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform_aug)\n",
        "trainloader_aug = torch.utils.data.DataLoader(trainset_aug, batch_size=256, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOix29PM38_L"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ, ëª¨ë¸ì˜ ëª¨ë“  ì¸µì„ í•™ìŠµì— ì°¸ì—¬ì‹œí‚¤ë„ë¡ ë™ê²°ì„ í•´ì œí•©ë‹ˆë‹¤. ì´ë¯¸ model ê°ì²´ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ë¶„ë¥˜ì¸µì´ í•™ìŠµëœ ìƒíƒœì´ë¯€ë¡œ ì´ë¥¼ ì´ì–´ì„œ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë™ê²°ì„ í’€ê¸° ìœ„í•´ ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ requires_gradë¥¼ ë‹¤ì‹œ Trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•˜ëŠ”ë°, ì´ì œëŠ” ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ê³ , í•™ìŠµë¥ ì€ ì¡°ê¸ˆ ë‚®ì¶°ì„œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤ (0.0005)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI_AXYg-3rnZ"
      },
      "outputs": [],
      "source": [
        "# ë¬¸ì œ 9: ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë™ê²°ì„ í•´ì œí•˜ì„¸ìš”\n",
        "# [START CODE]\n",
        "# --- ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ê²° í•´ì œ ---\n",
        "# requires_gradë¥¼ Trueë¡œ ì„¤ì •í•˜ì—¬ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ í•™ìŠµ ì¤‘ì— ì—…ë°ì´íŠ¸ë˜ë„ë¡ í•¨\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "# [END CODE]\n",
        "\n",
        "# --- ìƒˆë¡œìš´ ì˜µí‹°ë§ˆì´ì €ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì˜ ---\n",
        "# ì´ì œ model.parameters()ë¥¼ ì „ë‹¬í•˜ì—¬ ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™” ëŒ€ìƒìœ¼ë¡œ í•¨\n",
        "# í•™ìŠµë¥ (lr)ì€ ê¸°ì¡´ë³´ë‹¤ ì•½ê°„ ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ì„¬ì„¸í•˜ê²Œ ì¡°ì •\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUkuZSLg4I9a"
      },
      "source": [
        "í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ StepLRì„ ì‚¬ìš©í•˜ì—¬ ë§¤ 5 epochë§ˆë‹¤ í•™ìŠµë¥ ì„ 0.1ë°°ë¡œ ê°ì†Œì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤.\n",
        "ì´ëŠ” í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ ë” ë¯¸ì„¸í•œ ì¡°ì •ì„ í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµë¥ ì„ ì¤„ì—¬ ì£¼ì–´ ë” ì¢‹ì€ ìµœì í™”ë¥¼ ì´ë£¨ë„ë¡ ë•ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtkqRk7JxQRC"
      },
      "outputs": [],
      "source": [
        "# StepLR ìŠ¤ì¼€ì¤„ëŸ¬: íŠ¹ì • ë‹¨ê³„(step_size)ë§ˆë‹¤ í•™ìŠµë¥ ì— ê°ë§ˆ(gamma)ë¥¼ ê³±í•´ ê°ì†Œì‹œí‚´\n",
        "# step_size=5: 5 ì—í¬í¬ë§ˆë‹¤\n",
        "# gamma=0.1: í•™ìŠµë¥ ì„ 0.1ë°°ë¡œ ì¤„ì„\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG9XNSOM4We9"
      },
      "source": [
        "ì´ì œ ë¯¸ì„¸ ì¡°ì • ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ëŠ” ì•ì„œ ë¶„ë¥˜ì¸µë§Œ í•™ìŠµí•œ ê²ƒê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, ì´ë²ˆì—ëŠ” ì˜µí‹°ë§ˆì´ì €ì— ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ëŠ” ì ì´ ë‹¤ë¦…ë‹ˆë‹¤. ë˜í•œ ì•ì„œ ì •ì˜í•œ scheduler.step()ì„ ë§¤ epoch ëì— í˜¸ì¶œí•˜ì—¬ í•™ìŠµë¥ ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPgIyDQU4a51"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train() # í›ˆë ¨ ëª¨ë“œ\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # ì¦ê°•ì´ ì ìš©ëœ ë°ì´í„°ë¡œ í›ˆë ¨\n",
        "    for inputs, labels in trainloader_aug:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ì—í¬í¬ ê²°ê³¼ ì¶œë ¥\n",
        "    avg_loss = running_loss / len(trainloader_aug)\n",
        "    print(f\"[Fine-tune Epoch {epoch+1}/{num_epochs}] í‰ê·  í›ˆë ¨ ì†ì‹¤: {avg_loss:.4f}, í˜„ì¬ í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # ë¬¸ì œ 10: í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•´ í•™ìŠµë¥ ì„ ì¡°ì •í•˜ì„¸ìš”\n",
        "    # [START CODE]\n",
        "    # --- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ ---\n",
        "    # ì •ì˜ëœ ê·œì¹™ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì¡°ì •\n",
        "    scheduler.step()\n",
        "    # [END CODE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPuJGIGo4nSM"
      },
      "source": [
        "ì „ì²´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•œ í›„, ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ê³„ì‚°í•´ë³´ê² ìŠµë‹ˆë‹¤. 1ë‹¨ê³„(ì„ í˜• í”„ë¡œë¹™)ì™€ ë™ì¼í•œ ì ˆì°¨ë¡œ ì§„í–‰í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QsW6OHj4qrE"
      },
      "outputs": [],
      "source": [
        "# --- ë¯¸ì„¸ ì¡°ì • í›„ ëª¨ë¸ í‰ê°€ ---\n",
        "model.eval() # í‰ê°€ ëª¨ë“œ\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "fine_tune_acc = 100 * correct / total\n",
        "print(f\"ë¯¸ì„¸ ì¡°ì • í›„ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {fine_tune_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuOL3k924uh2"
      },
      "source": [
        "ì´ì œ 1ë‹¨ê³„ì—ì„œì˜ ì •í™•ë„ì™€ 2ë‹¨ê³„ ì „ì²´ ë¯¸ì„¸ ì¡°ì • í›„ ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kleYcCCqx74R"
      },
      "source": [
        "#  **3. HuggingFace Transformersë¥¼ í™œìš©í•œ ViT(Vision Transformer) ì¶”ë¡ **\n",
        "\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì‚¬ì „ í•™ìŠµëœ Vision Transformer (ViT) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ CIFAR-10 ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. ViTëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Transformer ì•„í‚¤í…ì²˜ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ë¡œ, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜(patch) ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë§ˆì¹˜ NLPì˜ í† í° ì‹œí€€ìŠ¤ì²˜ëŸ¼ ì¸ì‹í•©ë‹ˆë‹¤.\n",
        "\n",
        "HuggingFaceì˜ transformersì™€ datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì†ì‰½ê²Œ ì‚¬ì „ í•™ìŠµëœ ViT ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³ ,\n",
        "CIFAR-10 ì´ë¯¸ì§€ì— ëŒ€í•œ ë¶„ë¥˜ë¥¼ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "HuggingFace ëŠ” Pytorch ìƒíƒœê³„ì˜ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, HuggingFaceë¥¼ ì‚¬ìš©í•˜ë©´ ì‚¬ì „ í•™ìŠµëœ ìˆ˜ë§ì€ ëª¨ë¸ì„ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ì‰½ê²Œ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbsk1Nw2x-Wk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# HuggingFace Hubì—ì„œ CIFAR-10 ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜´\n",
        "# split='test'ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ë§Œ ê°€ì ¸ì˜¤ê² ë‹¤ëŠ” ì˜ë¯¸\n",
        "dataset = load_dataset('cifar10', split='test')\n",
        "\n",
        "# ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Komu3FyvKV"
      },
      "source": [
        "ì´ ë°ì´í„°ì…‹ ê°ì²´ì˜ ê° í•­ëª©ì€ `{'img': PIL.Image, 'label': ì •ìˆ˜ë ˆì´ë¸”}` í˜•íƒœë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Labelì˜ ì •ìˆ˜ê°’ê³¼ ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ì€ `dataset.features['label'].names`ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY18G2n3ypEt"
      },
      "outputs": [],
      "source": [
        "# ë ˆì´ë¸” ì¸ë±ìŠ¤ì™€ ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘\n",
        "labels = dataset.features['label'].names\n",
        "print(\"ë ˆì´ë¸” ëª©ë¡:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1z_3pJiy3Ri"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ, HuggingFace Hubì—ì„œ ì‚¬ì „ í•™ìŠµëœ ViT ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ViT ëª¨ë¸ ì¤‘, ì—¬ê¸°ì„œëŠ” ImageNet-21kë¡œ ì‚¬ì „ í•™ìŠµë˜ê³  CIFAR-10ì— ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "HuggingFaceì— ê³µê°œëœ `nateraw/vit-base-patch16-224-cifar10` ëª¨ë¸ì´ ì´ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ Googleì˜ ViT-Base ëª¨ë¸ì„ CIFAR-10ì— ë§ê²Œ Fine-Tuningí•œ ê²ƒìœ¼ë¡œ, CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•´ë‹¹ ëª¨ë¸ê³¼ í•¨ê»˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ViTFeatureExtractorë„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "ViTFeatureExtractorëŠ” ViT ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆ(224x224)í•˜ê³  ì •ê·œí™”í•´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
        "ìœ„ ì½”ë“œì—ì„œ ë¶ˆëŸ¬ì˜¨ feature_extractorëŠ” ë‚´ë¶€ì ìœ¼ë¡œ í•´ë‹¹ ëª¨ë¸ì— ë§ëŠ” ì´ë¯¸ì§€ ë³€í™˜(ì˜ˆ: ì •ê·œí™” ê°’ ë“±)ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ ViTForImageClassification ë„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "ViTForImageClassification í´ë˜ìŠ¤ëŠ” ì‚¬ì „ í•™ìŠµëœ ViT ëª¨ë¸ì— ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶œë ¥ì¸µì´ í¬í•¨ëœ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "nateraw/vit-base-patch16-224-cifar10 ëª¨ë¸ì€ CIFAR-10ìš©ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶œë ¥ì¸µì´ ì´ë¯¸ 10ê°œ ë‰´ëŸ°ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆê³ , ê° ë‰´ëŸ°ì€ CIFAR-10 í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ì— ëŒ€ì‘ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guSu1UQly17p"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "\n",
        "# ì‚¬ìš©í•  ëª¨ë¸ì˜ ì´ë¦„ (HuggingFace Hubì— ë“±ë¡ëœ ID)\n",
        "model_name = \"nateraw/vit-base-patch16-224-cifar10\"\n",
        "\n",
        "# ë¬¸ì œ 11: HuggingFace ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸°ë¥¼ ë¡œë“œí•˜ì„¸ìš”\n",
        "# [START CODE]\n",
        "# --- HuggingFace ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë“œ ---\n",
        "# from_pretrained() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë¥¼ ì‰½ê²Œ ë¶ˆëŸ¬ì˜´\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "vit_model = ViTForImageClassification.from_pretrained(model_name)\n",
        "# [END CODE]\n",
        "\n",
        "# ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
        "vit_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOnil29T5SSX"
      },
      "source": [
        "ì´ì œ ì¤€ë¹„ëœ ViT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¼ë¶€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•´ë³´ê² ìŠµë‹ˆë‹¤. ìš°ì„  CIFAR-10 í…ŒìŠ¤íŠ¸ ì…‹ì—ì„œ ëª‡ ê°œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ê² ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í…ŒìŠ¤íŠ¸ ì…‹ì˜ ì²˜ìŒ 5ê°œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewy0t0qyzEVN"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ì—ì„œ ì²˜ìŒ 5ê°œ ìƒ˜í”Œì˜ ì´ë¯¸ì§€ì™€ ì‹¤ì œ ë ˆì´ë¸” ì¶”ì¶œ\n",
        "sample_images = [dataset[i]['img'] for i in range(5)]\n",
        "true_index = [dataset[i]['label'] for i in range(5)]\n",
        "true_labels = [labels[dataset[i]['label']] for i in range(5)]\n",
        "print(\"ì‹¤ì œ ì¸ë±ìŠ¤:\", true_index)\n",
        "print(\"ì‹¤ì œ ë ˆì´ë¸”:\", true_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8h2rj0M5WJu"
      },
      "source": [
        "ê° imgëŠ” PIL ì´ë¯¸ì§€ ê°ì²´ì…ë‹ˆë‹¤. ViT ëª¨ë¸ì— ë„£ê¸° ì „ì— feature extractorë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  ë°°ì¹˜(batch) í˜•íƒœë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V6HW15L5VAb"
      },
      "outputs": [],
      "source": [
        "# --- FeatureExtractorë¡œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ---\n",
        "# PIL ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ì— ë§ëŠ” í…ì„œ í˜•íƒœë¡œ ë³€í™˜\n",
        "inputs = feature_extractor(images=sample_images, return_tensors=\"pt\")\n",
        "# ì „ì²˜ë¦¬ëœ ì…ë ¥ì„ GPUë¡œ ì´ë™\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "# --- ëª¨ë¸ ì¶”ë¡  ---\n",
        "with torch.no_grad(): # ì¶”ë¡  ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì´ í•„ìš” ì—†ìŒ\n",
        "    # **inputsëŠ” ë”•ì…”ë„ˆë¦¬ì˜ ê° í•­ëª©ì„ í•¨ìˆ˜ì˜ ì¸ìë¡œ í’€ì–´ ì „ë‹¬ (pixel_values=...)\n",
        "    outputs = vit_model(**inputs)\n",
        "\n",
        "# ëª¨ë¸ì˜ ì¶œë ¥(logits)ì—ì„œ ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì˜ˆì¸¡ í´ë˜ìŠ¤ë¡œ ì„ íƒ\n",
        "# predicted_class_idxsëŠ” 0ë¶€í„° 9 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ ì´ë£¨ì–´ì§„ ë°°ì—´ì´ë©°,\n",
        "# ê° ìˆ«ìëŠ” CIFAR-10 í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "# ì´ë¥¼ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì•ì„œ ì–»ì€ labels ë¦¬ìŠ¤íŠ¸ë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
        "predicted_class_idxs = outputs.logits.argmax(dim=1).cpu().numpy()\n",
        "# ì˜ˆì¸¡ëœ ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜\n",
        "predicted_labels = [labels[idx] for idx in predicted_class_idxs]\n",
        "\n",
        "print(\"ëª¨ë¸ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤:\", predicted_class_idxs)\n",
        "print(\"ëª¨ë¸ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¼ë²¨:\", predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPTvM-lI5one"
      },
      "source": [
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì˜ˆì‹œ ì´ë¯¸ì§€ë“¤ê³¼ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë ˆì´ë¸”ì„ í•¨ê»˜ ì‹œê°í™”í•´ë³´ê² ìŠµë‹ˆë‹¤. Matplotlibë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ê³ , ì œëª©ì— ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P4glEhO5nZU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- ê²°ê³¼ ì‹œê°í™” ---\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, img in enumerate(sample_images):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    # ì´ë¯¸ì§€ ì œëª©ì— ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ì •ë‹µ í‘œì‹œ\n",
        "    plt.title(f\"Pred: {predicted_labels[i]}\\nTrue: {true_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY9zqMAA5zmC"
      },
      "source": [
        " HuggingFaceì˜ pipelineì„ ì‚¬ìš©í•˜ë©´ ìœ„ ê³¼ì •ì„ ë” ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        " ì™€ ê°™ì´ í•˜ë©´ ì´ë¯¸ì§€ë§ˆë‹¤ ì˜ˆì¸¡ëœ ë ˆì´ë¸”ê³¼ ì‹ ë¢°ë„(score)ë¥¼ ì‰½ê²Œ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. pipelineì€ ë‚´ë¶€ì ìœ¼ë¡œ feature extractorì™€ ëª¨ë¸ ì˜ˆì¸¡ ê³¼ì •ì„ ìº¡ìŠí™”í•˜ì—¬ í¸ì˜ì„±ì„ ì œê³µí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_WKeAdE51ed"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "# ì´ë¯¸ì§€ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "clf = pipeline(\"image-classification\",\n",
        "               model=model_name, device=device)\n",
        "\n",
        "# ë¬¸ì œ 12: íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì„¸ìš”\n",
        "# íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "# [START CODE]\n",
        "preds = clf(\"cat_image.jpg\")   # ì˜ˆì‹œ: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
        "# [END CODE]\n",
        "\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKJZ9Q6a83Tv"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "clf = pipeline(\"image-classification\", model=model_name)\n",
        "preds = clf(sample_images)\n",
        "\n",
        "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë” ì½ê¸° ì‰½ê²Œ ì¶œë ¥\n",
        "print(\"Pipeline ì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "for i, pred_list in enumerate(preds):\n",
        "    print(f\"ì´ë¯¸ì§€ {i+1}:\")\n",
        "    for pred in pred_list:\n",
        "        # 'LABEL_X' ë¬¸ìì—´ì—ì„œ ë ˆì´ë¸” ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
        "        label_index = int(pred['label'].split('_')[1])\n",
        "        print(f\"  - ë ˆì´ë¸”: {labels[label_index]}, ì‹ ë¢°ë„: {pred['score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc9k0nR06k0P"
      },
      "source": [
        "# **ë§ˆì¹˜ë©°**\n",
        "\n",
        "\n",
        "ì´ìƒìœ¼ë¡œ CIFAR-10ì„ í™œìš©í•œ ì»´í“¨í„° ë¹„ì „ AI ì„ ì‹¤ìŠµí•´ ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì„¹ì…˜ 1ì—ì„œëŠ” ResNet-18 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì¸µë§Œ í•™ìŠµí•˜ëŠ” ì„ í˜• í”„ë¡œë¹™ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì„±ëŠ¥ì„ ì–»ëŠ” ë°©ë²•ì„, ì„¹ì…˜ 2ì—ì„œëŠ” ë°ì´í„° ì¦ê°•ê³¼ ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìœ¼ë©°, ì„¹ì…˜ 3ì—ì„œëŠ” HuggingFaceì˜ ì‚¬ì „ í•™ìŠµ ViT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì†ì‰½ê²Œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ë²•ë“¤ì€ ì‹¤ì œ ì»´í“¨í„° ë¹„ì „ ê³¼ì œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ë“¤ì´ë©°, ì£¼ì–´ì§„ ì˜ˆì‹œ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‘ìš©ì„ ì‹œë„í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}